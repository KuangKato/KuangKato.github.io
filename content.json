{"meta":{"title":"Better than yesterday","subtitle":null,"description":null,"author":"Kuanger","url":"http://www.kuanger.top"},"pages":[{"title":"About Me","date":"2018-11-29T14:55:25.000Z","updated":"2018-11-30T07:31:12.384Z","comments":true,"path":"about/index.html","permalink":"http://www.kuanger.top/about/index.html","excerpt":"","text":"孔子云：取乎其上，得乎其中；取乎其中，得乎其下；取乎其下，则无所得矣。 “ 在科技道路上不断爬行的一个普通人。” 个人博客，用于分享一些在日常学习工作甚至于生活中遇到的一些比较有趣的东西。七荤八素，胡言乱语，望各位看官见谅。 个人联系方式 Email： kuang_kato@163.com Phone： 13168844985"},{"title":"categories","date":"2018-11-29T14:54:45.000Z","updated":"2018-11-29T14:56:33.380Z","comments":true,"path":"categories/index.html","permalink":"http://www.kuanger.top/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-11-29T14:53:19.000Z","updated":"2018-11-29T14:55:58.165Z","comments":true,"path":"tags/index.html","permalink":"http://www.kuanger.top/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"阿里巴巴Java开发手册中的开发规约之一(3)","slug":"backend/规约/阿里巴巴Java开发手册中的开发规约之一(3)","date":"2019-01-13T16:00:00.000Z","updated":"2019-01-16T11:50:18.894Z","comments":true,"path":"2019/01/14/backend/规约/阿里巴巴Java开发手册中的开发规约之一(3)/","link":"","permalink":"http://www.kuanger.top/2019/01/14/backend/规约/阿里巴巴Java开发手册中的开发规约之一(3)/","excerpt":"包装类比较 【强制】所有的相同类型的包装类对象之间值的比较，全部使用 equals 方法比较。 说明： 对于 Integer var=? 在-128 至 127 之间的赋值， Integer 对象是在IntegerCache.cache 产生，会复用已有对象，这个区间内的 Integer 值可以直接使用 == 进行判断，但是这个区间之外的所有数据，都会在堆上产生，并不会复用已有对象，这是一个大坑，推荐使用 equals 方法进行判断。","text":"包装类比较 【强制】所有的相同类型的包装类对象之间值的比较，全部使用 equals 方法比较。 说明： 对于 Integer var=? 在-128 至 127 之间的赋值， Integer 对象是在IntegerCache.cache 产生，会复用已有对象，这个区间内的 Integer 值可以直接使用 == 进行判断，但是这个区间之外的所有数据，都会在堆上产生，并不会复用已有对象，这是一个大坑，推荐使用 equals 方法进行判断。 举例：12345678910111213141516@Testpublic void test()&#123; Integer integer1 = new Integer(1); Integer integer2 = new Integer(1); System.out.println(integer1 == integer2);//false Integer integer3 = 1; Integer integer4 = 1; System.out.println(integer3 == integer4);//true System.out.println(integer1 == integer4);//false Integer integer5 = 128; Integer integer6 = 128; System.out.println(integer5 == integer6);//false&#125; ArrayList.subList 【强制】 ArrayList的subList结果不可强转成ArrayList，否则会抛出 ClassCastException 异常 ： java.util.RandomAccessSubList cannot be cast to java.util.ArrayList; 说明： subList 返回的是 ArrayList 的内部类 SubList，并不是 ArrayList ，而是 ArrayList 的一个视图，对于 SubList 子列表的所有操作最终会反映到原列表上。 123456789101112131415161718@Testpublic void test()&#123; List&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(\"a\"); System.out.println(list); //[a] // 使用构造器创建一个包含list的列表list1 List&lt;String&gt; list1 = new ArrayList&lt;String&gt;(list); // 使用subList生成与list相同的列表list2 List&lt;String&gt; list2 = list.subList(0, list.size()); list2.add(\"b\"); System.out.println(list1);//[a] System.out.println(list);//[a,b] System.out.println(list2);//[a,b] System.out.println(list.equals(list1)); System.out.println(list.equals(list2));&#125; Arrays.asList() 【强制】使用工具类 Arrays.asList() 把数组转换成集合时，不能使用其修改集合相关的方法，它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。 说明： asList 的返回对象是一个 Arrays 内部类，并没有实现集合的修改方法。Arrays.asList 体现的是适配器模式，只是转换接口，后台的数据仍是数组。 12String[] str = new String[] &#123; \"a\", \"b\" &#125;;List list = Arrays.asList(str); 第一种情况： list.add(&quot;c&quot;); 运行时异常。 第二种情况： str[0]= &quot;gujin&quot;; 那么 list.get(0)也会随之修改。 详细说明 报错信息1234Exception in thread \"main\" java.lang.UnsupportedOperationException at java.util.AbstractList.add(AbstractList.java:148) at java.util.AbstractList.add(AbstractList.java:108) at com.liu.date20170702.TestArrayToList.main(TestArrayToList.java:17) 当我们调用add()方法时抛出了异常。我们顺着堆栈信息往上找，提示的是AbstractList类的108行出了异常，这一行所在方法的具体实现如下： 1234public boolean add(E e) &#123; add(size(), e); return true;&#125; 出现异常的第108行调用了add()方法，于是继续寻找这个add()方法的实现，具体如下： 123public void add(int index, E element) &#123; throw new UnsupportedOperationException();&#125; 到这里我们找到了异常抛出的地方，但是如果要找到真正的原因，我们还需要看下示例代码中的 asList() 方法的实现，具体如下： 123public static &lt;T&gt; List&lt;T&gt; asList(T... a) &#123; return new ArrayList&lt;&gt;(a);&#125; 可以发现，他返回的是一个ArrayList，但此ArrayList不是彼ArrayList。这个ArrayList是Arrays工具类中实现的 内部静态类 ，跟在java.util包中ArrayList不同。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192private static class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements RandomAccess, java.io.Serializable&#123; private static final long serialVersionUID = -2764017481108945198L; private final E[] a; ArrayList(E[] array) &#123; a = Objects.requireNonNull(array); &#125; @Override public int size() &#123; return a.length; &#125; @Override public Object[] toArray() &#123; return a.clone(); &#125; @Override @SuppressWarnings(\"unchecked\") public &lt;T&gt; T[] toArray(T[] a) &#123; int size = size(); if (a.length &lt; size) return Arrays.copyOf(this.a, size, (Class&lt;? extends T[]&gt;) a.getClass()); System.arraycopy(this.a, 0, a, 0, size); if (a.length &gt; size) a[size] = null; return a; &#125; @Override public E get(int index) &#123; return a[index]; &#125; @Override public E set(int index, E element) &#123; E oldValue = a[index]; a[index] = element; return oldValue; &#125; @Override public int indexOf(Object o) &#123; E[] a = this.a; if (o == null) &#123; for (int i = 0; i &lt; a.length; i++) if (a[i] == null) return i; &#125; else &#123; for (int i = 0; i &lt; a.length; i++) if (o.equals(a[i])) return i; &#125; return -1; &#125; @Override public boolean contains(Object o) &#123; return indexOf(o) != -1; &#125; @Override public Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(a, Spliterator.ORDERED); &#125; @Override public void forEach(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); for (E e : a) &#123; action.accept(e); &#125; &#125; @Override public void replaceAll(UnaryOperator&lt;E&gt; operator) &#123; Objects.requireNonNull(operator); E[] a = this.a; for (int i = 0; i &lt; a.length; i++) &#123; a[i] = operator.apply(a[i]); &#125; &#125; @Override public void sort(Comparator&lt;? super E&gt; c) &#123; Arrays.sort(a, c); &#125;&#125; 可以发现，这个类集成了 AbstractList 类，但是并没有重写add()方法，所以在我们调用 add() 方法时，实际是调用 父类AbstractList 的 add()方法，这也就回到了开头分析的那两个add()方法了，它们都没有具体实现，只会抛出UnsupportedOperationException。 原因总结 到这里我们可以稍稍理清下思路了，我们调用Arrays的asList()方法将数组转换成List时返回的是Arrays的静态内部类ArrayList，它自身并未重写add()方法，而其父类AbstractList实现的add()方法只会抛出UnsupportedOperationException，导致我们调用Arrays的静态内部类ArrayList的add()方法时，实际调用的是只会抛出UnsupportedOperationException的AbstractList的add()方法，这就是异常出现的原因了。","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"规范","slug":"规范","permalink":"http://www.kuanger.top/tags/规范/"}]},{"title":"HashMap的源码分析","slug":"backend/java_基础/HashMap的源码分析","date":"2019-01-07T16:00:00.000Z","updated":"2019-01-16T15:40:03.388Z","comments":true,"path":"2019/01/08/backend/java_基础/HashMap的源码分析/","link":"","permalink":"http://www.kuanger.top/2019/01/08/backend/java_基础/HashMap的源码分析/","excerpt":"HashMap 内部的结构HashMap 它可以看作是 数组（Node&lt;K,V&gt;[] table） 和 链表 结合组成的复合结构，数组被分为一个个 桶（bucket），通过哈希值决定了键值对在这个数组的寻址；哈希值相同的键值对，则以链表形式存储，你可以参考下面的示意图。这里需要注意的是，如果链表大小超过阈值（TREEIFY_THRESHOLD, 8），图中的链表就会被改造为树形结构。","text":"HashMap 内部的结构HashMap 它可以看作是 数组（Node&lt;K,V&gt;[] table） 和 链表 结合组成的复合结构，数组被分为一个个 桶（bucket），通过哈希值决定了键值对在这个数组的寻址；哈希值相同的键值对，则以链表形式存储，你可以参考下面的示意图。这里需要注意的是，如果链表大小超过阈值（TREEIFY_THRESHOLD, 8），图中的链表就会被改造为树形结构。 HashMap的类加载会有一些静态属性进行赋值。 123456789101112131415// 初始容量值，必须是2的整数次幂static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16// 当我们设置初始化默认值的时候，最大的容量值，必须是2的整数次幂static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;// 扩容的时候需要的加载因子static final float DEFAULT_LOAD_FACTOR = 0.75f;// 当链条需要进行树化的阈值static final int TREEIFY_THRESHOLD = 8;static final int UNTREEIFY_THRESHOLD = 6;static final int MIN_TREEIFY_CAPACITY = 64; 从构造方法开始 默认构造方法 1234// 只给初始容量赋值public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted 1&lt;&lt;4 即16&#125; 从构造方法可以看得出来，HashMap 也许是按照 lazy-load 原则，在首次使用时才被初始化（拷贝构造函数除外） 带初始容量的构造方法 1234public HashMap(int initialCapacity) &#123; // 会调用另一个构造方法，带初始容量和加载因子, DEFAULT_LOAD_FACTOR = 1&lt;&lt;4 this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125; 带初始容量和加载因子的构造方法 12345678910111213141516public HashMap(int initialCapacity, float loadFactor) &#123; // 判断传入的初始容量是否负数 if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); // 判断初始容量是否大于最大容量值 1&lt;&lt;30 即是int的最大值 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // 判断传入的加载因子是否正规 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; // 计算大于等于参数且最小2的幂 this.threshold = tableSizeFor(initialCapacity);&#125; tableSizeFor 可以看一下这个 tableSizeFor 算法，比较有艺术感 12345678910111213141516171819202122232425262728293031323334353637383940414243/*** Returns a power of two size for the given target capacity.*/static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125;这个方法是在找大于等于cap且最小2的幂比如cap=1 结果 2 0次方 1cap=2 2cap=3 4cap=9 16分析下等于9cap - 1 第一步结果800000000000000000000000000001000 800000000000000000000000000000100 右移1位 00000000000000000000000000001100 或运算 结果00000000000000000000000000000011 右移2位00000000000000000000000000001111 或运算 结果00000000000000000000000000001111 右移 4 8 16没用全是0结果还是这个15最终 +1 16分析下等于大点 1234567800000000101111000110000101001110 1234567800000000101111000110000101001101 -1结果 1234567700000000010111100011000010100110 右移1位 00000000111111100111000111101111 或运算 结果00000000001111111001110001111011 右移2位00000000111111111111110111111111 差不多了在移0就没了都是1了，+1不是肯定是2的倍数了再说开始-1原因这是为了防止，cap已经是2的幂。如果cap已经是2的幂， 又没有执行这个减1操作，则执行完后面的几条无符号右移操作之后，返回的capacity将是这个cap的2倍。 Put操作先看常用的 put键值对，这个学完了，那么其他的put方法就没什么问题了，比如 putAll、putIfAbsent、putMapEntries， 取值就是一个反向就简单了 123public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125; hash 先对key进行hash计算，学一下 1234567static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); // 1. 看出key是可以空的 hash为0 // 2. hashcode是32位的，无符号右移16位，那生成的就是16位0加原高位的16位值， 就是对半了，异或计算也就变成了高16位和低16位进行异或，原高16位不变。 // 这么干主要用于当hashmap 数组比较小的时候所有bit都参与运算了，防止hash冲突太大，所谓hash冲突是指不同的key计算出的hash是一样的，比如a和97，这个肯定是存在的没毛病,这样做可以有效避免类似情况下的哈希碰撞&#125; putVal putVal 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/*** Implements Map.put and related methods** @param hash hash for key* @param key the key* @param value the value to put* @param onlyIfAbsent if true, don't change existing value //如果为true就不改变原本的value* @param evict if false, the table is in creation mode. //在hashmap中没用* @return previous value, or null if none*/final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; // 申明变量，可以在下方看 Node的键值对节点数据结构 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) // 如果表格是 null，resize 方法会负责初始化它，下方再介绍resize()他的两个职责 n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null)//通过计算的hash去映射，并检测数组头是否为空 tab[i] = newNode(hash, key, value, null);//为空则直接创建新的节点 else &#123; // 如果有数据则hash相同,申明变量进行下方判断 Node&lt;K,V&gt; e; K k; // 如果hash相同和key都相同,则获取此节点到下方判断是否覆盖 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode)// 判断一下节点类型，如果是已经树化则调用红黑树的插入 e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //对链表进行遍历匹配 for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; //如果下一个节点为空则插入 p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash);// 如果链条的长度超过树化阈值则进行树化 break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break;//获取hash和key相同的节点 p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key 判断是否获取到节点 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null)// 判断传入参数是否要进行覆盖 e.value = value;//如果是进行覆盖 // 此方法是空代码 作用是给LinkedHashMap进行继承重写 afterNodeAccess(e);//包括afterNodeAccess、afterNodeRemoval return oldValue; &#125; &#125; ++modCount;// 每次操作对modCount维护，因为fail-fast机制 // threshold = (capacity * load factor)，在resize()里面维护 if (++size &gt; threshold) resize();// 如果在放置新的键值对的过程中，如果发生上面条件，就会发生扩容 //LinkedHashMap中被覆盖的afterNodeInsertion方法，用来回调移除最早放入Map的对象 afterNodeInsertion(evict); return null;&#125; Node键值对的节点数据结构 12345678910111213141516171819202122232425262728293031323334353637383940414243/*** Basic hash bin node, used for most entries. (See below for* TreeNode subclass, and in LinkedHashMap for its Entry subclass.)*/static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; public final K getKey() &#123; return key; &#125; public final V getValue() &#123; return value; &#125; public final String toString() &#123; return key + \"=\" + value; &#125; public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125;&#125; resize()方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/*** Initializes or doubles table size. If null, allocates in* accord with initial capacity target held in field threshold.* Otherwise, because we are using power-of-two expansion, the* elements from each bin must either stay at same index, or move* with a power of two offset in the new table.* * @return the table*///主要肩负两个职责：负责初始化和扩容final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123;// 旧容量的长度大于等于最大容量则设置阈值为1&lt;&lt;30 返回旧的table threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;//旧容量的长度小于最大容量和超过阈值 则扩容2倍 oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults 如果是0就是初始化 计算默认值 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; //初始化table或者扩容, 实际上都是通过新建一个table来完成的 所以耗能也大 @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 移动到新的数组结构 e 数组结构 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123;//遍历 Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null;//清除旧表的node，节点还在e if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e;//如果是null直接put进去 else if (e instanceof TreeNode)//判断是节点类型 直接调用红黑树的方法 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order // 下面这段代码很精妙, 是链表拆分，单独分一段详细来讲 Node&lt;K,V&gt; loHead = null, loTail = null;//一个lo头和lo链 Node&lt;K,V&gt; hiHead = null, hiTail = null;//一个hi头和hi链 Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123;//进行链表拆分 if (loTail == null)// 插入lo链表 loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null)// 插入hi链表 hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123;//如果lo链表非空, 我们就把整个lo链表放到新table的j位置上 loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123;//如果hi链表非空, 我们就把整个hi链表放到新table的j+oldCap位置上 hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 看到上面的链表拆分，综上我们知道, 这段代码的意义就是将原来的链表拆分成两个链表, 并将这两个链表分别放到新的table的 j 位置和 j+oldCap 上, j位置就是原链表在原table中的位置, 拆分的标准就是: 1(e.hash &amp; oldCap) == 0 可以参考图片 说明一下 (e.hash &amp; oldCap) == 0首先需要明确的是： oldCap一定是2的整数次幂, 这里假设是 2^m newCap是oldCap的两倍, newCap = oldCap &lt;&lt; 1 , 则会是 2^(m+1) hash对数组大小取模 (n - 1) &amp; hash 其实就是取 hash的低m位, 即n最低2的m整数次幂 1234567我们假设 oldCap = 1 &lt;&lt;4, 即 2^4, 即16二进制为： 00000000 00000000 00000000 00010000 即0x0001000016 - 1为： 00000000 00000000 00000000 00001111 即0x00001111若oldCap扩容2倍 oldCap &lt;&lt; 1 即 2^5 即32二进制为： 00000000 00000000 00000000 00100000 即0x0010000032 - 1为： 00000000 00000000 00000000 00011111 即0x00011111 可见16中除了低4位, 其他位置都是0,（简洁起见，高位的0后面就不写了） 则 (16-1) &amp; hash 自然就是取hash值的低4位,我们假设低4位值为 0xabcd,在16即为0x1111. 当我们将oldCap扩大两倍后, 新的index的位置就变成了 (32-1) &amp; hash, 其实就是取 hash值的低5位为 0x1abcd,在32即为0x11111。 那么对于同一个Node, 低5位的值无外乎下面两种情况:123452^m (m=4):0xabcd 高位为0，若取5位: 0x0abcd2^(m+1) (m=4):0x1abcd 0x1abcd16:0x0111132:0x11111 其中, 0xabcd与原来的index值一致, 而 1abcd = 0abcd + 10000 (左移一位) = 0abcd + oldCap 故虽然数组大小扩大了一倍，但是同一个key在新旧table中对应的index却存在一定联系： 要么一致，要么相差一个 oldCap。 故得出结论: 如果 (e.hash &amp; oldCap) == 0 则该节点在新表的下标位置与旧表一致都为 j 如果 (e.hash &amp; oldCap) == 1 则该节点在新表的下标位置 j + oldCap 根据这个条件, 我们将原位置的链表拆分成两个链表, 然后一次性将整个链表放到新的Table对应的位置上. treeifyBin()树化方法1234567891011121314151617181920212223242526272829/*** Replaces all linked nodes in bin at index for given hash unless* table is too small, in which case resizes instead.*/final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; //如果table的长度即容量小于 MIN_TREEIFY_CAPACITY，只会进行简单的扩容。 MIN_TREEIFY_CAPACITY = 64 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); //如果table的长度即容量大于 MIN_TREEIFY_CAPACITY ，则会进行树化改造。 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123;//根据hash值和数组长度进行取模运算后，得到链表的首节点 TreeNode&lt;K,V&gt; hd = null, tl = null;// 定义首、尾节点 do &#123; TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null);// 将该节点转换为 树节点 if (tl == null)// 如果尾节点为空，说明还没有根节点 hd = p; // 首节点（根节点）指向 当前节点 else &#123;// 尾节点不为空，以下两行是一个双向链表结构 p.prev = tl; // 当前树节点的 前一个节点指向 尾节点 tl.next = p; // 尾节点的 后一个节点指向 当前节点 &#125; tl = p; // 把当前节点设为尾节点 &#125; while ((e = e.next) != null);// 继续遍历链表 // 到目前为止 也只是把Node对象转换成了TreeNode对象，把单向链表转换成了双向链表 // 把转换后的双向链表，替换原来位置上的单向链表 if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125; treeify()方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263/*** Forms tree of the nodes linked from this node.* @return root of tree*/final void treeify(Node&lt;K,V&gt;[] tab) &#123;//参数为HashMap的元素数组 TreeNode&lt;K,V&gt; root = null;// 定义树的根节点 for (TreeNode&lt;K,V&gt; x = this, next; x != null; x = next) &#123;// 遍历链表，x指向当前节点、next指向下一个节点 next = (TreeNode&lt;K,V&gt;)x.next;// 下一个节点 x.left = x.right = null; // 设置当前节点的左右节点为空 if (root == null) &#123; // 如果还没有根节点 x.parent = null; // 当前节点的父节点设为空 x.red = false; // 当前节点的红色属性设为false（把当前节点设为黑色） root = x; // 根节点指向到当前节点 &#125; else &#123; // 如果已经存在根节点了 K k = x.key; // 取得当前链表节点的key int h = x.hash; // 取得当前链表节点的hash值 Class&lt;?&gt; kc = null; // 定义key所属的Class for (TreeNode&lt;K,V&gt; p = root;;) &#123; // 从根节点开始遍历，此遍历没有设置边界，只能从内部跳出 // GOTO1 int dir, ph; // dir 标识方向（左右）、ph标识当前树节点的hash值 K pk = p.key; // 当前树节点的key if ((ph = p.hash) &gt; h) // 如果当前树节点hash值 大于 当前链表节点的hash值 dir = -1; // 标识当前链表节点会放到当前树节点的左侧 else if (ph &lt; h) dir = 1; // 右侧 /* * 如果两个节点的key的hash值相等，那么还要通过其他方式再进行比较 * 如果当前链表节点的key实现了comparable接口，并且当前树节点和链表节点是相同Class的实例，那么通过comparable的方式再比较两者。 * 如果还是相等，最后再通过tieBreakOrder比较一次 */ else if ((kc == null &amp;&amp; (kc = comparableClassFor(k)) == null) || (dir = compareComparables(kc, k, pk)) == 0) dir = tieBreakOrder(k, pk); TreeNode&lt;K,V&gt; xp = p; // 保存当前树节点 /* * 如果dir 小于等于0 ： 当前链表节点一定放置在当前树节点的左侧，但不一定是该树节点的左孩子，也可能是左孩子的右孩子 或者 更深层次的节点。 * 如果dir 大于0 ： 当前链表节点一定放置在当前树节点的右侧，但不一定是该树节点的右孩子，也可能是右孩子的左孩子 或者 更深层次的节点。 * 如果当前树节点不是叶子节点，那么最终会以当前树节点的左孩子或者右孩子 为 起始节点 再从GOTO1 处开始 重新寻找自己（当前链表节点）的位置 * 如果当前树节点就是叶子节点，那么根据dir的值，就可以把当前链表节点挂载到当前树节点的左或者右侧了。 * 挂载之后，还需要重新把树进行平衡。平衡之后，就可以针对下一个链表节点进行处理了。 */ if ((p = (dir &lt;= 0) ? p.left : p.right) == null) &#123; x.parent = xp; // 当前链表节点 作为 当前树节点的子节点 if (dir &lt;= 0) xp.left = x; // 作为左孩子 else xp.right = x; // 作为右孩子 root = balanceInsertion(root, x); // 重新平衡 break; &#125; &#125; &#125; &#125; // 把所有的链表节点都遍历完之后，最终构造出来的树可能经历多个平衡操作，根节点目前到底是链表的哪一个节点是不确定的 // 因为我们要基于树来做查找，所以就应该把 tab[N] 得到的对象一定根节点对象，而目前只是链表的第一个节点对象，所以要做相应的处理。 moveRootToFront(tab, root);&#125; 分析： https://me.csdn.net/weixin_42340670 重新平衡 balanceInsertion ： https://blog.csdn.net/weixin_42340670/article/details/80550932 moveRootToFront：https://blog.csdn.net/weixin_42340670/article/details/80555860 Get操作12345public V get(Object key) &#123; Node&lt;K,V&gt; e; // 判断调用getNode获取的节点是否为空，否则返回value return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; getNode()方法12345678910111213141516171819202122232425262728/*** Implements Map.get and related methods** @param hash hash for key* @param key the key* @return the node, or null if none*/final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; if (first.hash == hash &amp;&amp; //always check first node判断第一个节点的hash和key是否相同则直接返回 ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; // 如果节点类型是红黑树则调用红黑树获取节点方法 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 遍历节点判断hash和key是否相同则直接返回 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 解决哈希冲突的常用方法Hash一些理解Hash，一般翻译做 “散列”，也有直接音译为 “哈希” 的，就是把任意长度的输入（又叫做预映射， pre-image） 通过散列算法，变换成固定长度的输出，该输出就是散列值。这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，而不可能从散列值来唯一的确定输入值。","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"java基础","slug":"java基础","permalink":"http://www.kuanger.top/tags/java基础/"}]},{"title":"Map集合","slug":"backend/java_基础/Map集合","date":"2019-01-04T16:00:00.000Z","updated":"2019-01-16T12:09:23.639Z","comments":true,"path":"2019/01/05/backend/java_基础/Map集合/","link":"","permalink":"http://www.kuanger.top/2019/01/05/backend/java_基础/Map集合/","excerpt":"MapMap 是广义 Java 集合框架中的另外一部分，Hashtable、HashMap、TreeMap 都是最常见的一些 Map 实现，是以键值对的形式存储和操作数据的容器类型。 典型回答 Hashtable 是早期 Java 类库提供的一个 哈希表 实现，本身是同步的，不支持 null 键和值，由于同步导致的性能开销，所以已经很少被推荐使用。 HashMap 是应用更加广泛的哈希表实现，行为上大致上与 HashTable 一致，主要区别在于 HashMap 不是同步的，支持 null 键和值等。通常情况下，HashMap 进行 put 或者 get 操作，可以达到常数时间的性能，所以它是绝大部分利用键值对存取场景的首选，比如，实现一个用户 ID 和用户信息对应的运行时存储结构。 TreeMap 则是基于红黑树的一种提供顺序访问的 Map，和 HashMap 不同，它的 get、put、remove 之类操作都是 O（log(n)）的时间复杂度，具体顺序可以由指定的 Comparator 来决定，或者根据键的自然顺序来判断。 HashMap 在并发环境可能出现 无限循环占用 CPU 、size 不准确等诡异的问题。我认为这是一种典型的使用错误，因为 HashMap 明确声明不是线程安全的数据结构，如果忽略这一点，简单用在多线程场景里，难免会出现问题。 理解导致这种错误的原因，也是深入理解并发程序运行的好办法。对于具体发生了什么，你可以参考这篇很久以前的 分析 。","text":"MapMap 是广义 Java 集合框架中的另外一部分，Hashtable、HashMap、TreeMap 都是最常见的一些 Map 实现，是以键值对的形式存储和操作数据的容器类型。 典型回答 Hashtable 是早期 Java 类库提供的一个 哈希表 实现，本身是同步的，不支持 null 键和值，由于同步导致的性能开销，所以已经很少被推荐使用。 HashMap 是应用更加广泛的哈希表实现，行为上大致上与 HashTable 一致，主要区别在于 HashMap 不是同步的，支持 null 键和值等。通常情况下，HashMap 进行 put 或者 get 操作，可以达到常数时间的性能，所以它是绝大部分利用键值对存取场景的首选，比如，实现一个用户 ID 和用户信息对应的运行时存储结构。 TreeMap 则是基于红黑树的一种提供顺序访问的 Map，和 HashMap 不同，它的 get、put、remove 之类操作都是 O（log(n)）的时间复杂度，具体顺序可以由指定的 Comparator 来决定，或者根据键的自然顺序来判断。 HashMap 在并发环境可能出现 无限循环占用 CPU 、size 不准确等诡异的问题。我认为这是一种典型的使用错误，因为 HashMap 明确声明不是线程安全的数据结构，如果忽略这一点，简单用在多线程场景里，难免会出现问题。 理解导致这种错误的原因，也是深入理解并发程序运行的好办法。对于具体发生了什么，你可以参考这篇很久以前的 分析 。 Map 整体结构 元素特征 在阿里巴巴手册中也有注意说明Map类集合K/V的存储情况；对于 TreeMap 中 Key 能不能为null，可以取决于Comparator接口，当实现Comparator接口时，若未对null情况进行判断，则key不可以为null，反之亦然。 顺序特性 HashTable、HashMap具有无序特性。 TreeMap是利用红黑树来实现的 红黑树特点 树中的每个左子树都小于等于父节点 树中的每个右子树都大于等于父节点 实现了 SortedMap接口 ，能够对保存的记录根据键进行排序。 一般需要排序的情况下是选择TreeMap进行，默认为升序排序（深度优先搜索），也可以自定义实现 Comparator接口 实现排序方式，或 Comparable接口（自然顺序）。使用场景也就是自定义排序. LinkedHashMap 通常提供的是遍历顺序符合插入顺序，它的实现是通过为条目（键值对）维护一个双向链表。注意，通过特定构造函数，我们可以创建反映访问顺序的实例，所谓的 put、get、compute 等，都算作“访问”。 对于 LinkedHashMap 适用于一些特定应用场景，例如，我们构建一个空间占用敏感的资源池，希望可以自动将最不常被访问的对象释放掉，这就可以利用 LinkedHashMap 提供的机制来实现，参考下面的示例： 1234567891011121314151617181920212223242526272829303132import java.util.LinkedHashMap;import java.util.Map; public class LinkedHashMapSample &#123; public static void main(String[] args) &#123; LinkedHashMap&lt;String, String&gt; accessOrderedMap = new LinkedHashMap&lt;&gt;(16, 0.75F, true)&#123; @Override protected boolean removeEldestEntry(Map.Entry&lt;String, String&gt; eldest) &#123; // 实现自定义删除策略，否则行为就和普遍 Map 没有区别 return size() &gt; 3; &#125; &#125;; accessOrderedMap.put(\"Project1\", \"Valhalla\"); accessOrderedMap.put(\"Project2\", \"Panama\"); accessOrderedMap.put(\"Project3\", \"Loom\"); accessOrderedMap.forEach( (k,v) -&gt; &#123; System.out.println(k +\":\" + v); &#125;); // 模拟访问 accessOrderedMap.get(\"Project2\"); accessOrderedMap.get(\"Project2\"); accessOrderedMap.get(\"Project3\"); System.out.println(\"Iterate over should be not affected:\"); accessOrderedMap.forEach( (k,v) -&gt; &#123; System.out.println(k +\":\" + v); &#125;); // 触发删除 accessOrderedMap.put(\"Project4\", \"Mission Control\"); System.out.println(\"Oldest entry should be removed:\"); accessOrderedMap.forEach( (k,v) -&gt; &#123;// 遍历顺序不变 System.out.println(k +\":\" + v); &#125;); &#125;&#125; 初始化和增长方式 初始化时： HashTable在不指定容量的情况下默认容量为11，且不要求底层数组的容量一定要为2的整数次幂； HashMap默认容量为 1 &lt;&lt; 4 (为16)，且要求容量一定为2的整数次幂。 扩容时： HashTable 将容量扩容到原来的2倍加1 HashMap 将容量扩容带原来的2倍 线程安全 HashTable 其方法函数都是同步的（采用synchronized修饰），不会出现两个线程同时对数据进行操作的情况，因此保证了线程安全性。 也正因为如此，在多线程运行环境下效率表现非常低下。因为当一个线程访问HashTable的同步方法时，其他线程也访问同步方法就会进入阻塞状态。比如当一个线程在添加数据时候，另外一个线程即使执行获取其他数据的操作也必须被阻塞，大大降低了程序的运行效率，在新版本中已被废弃，不推荐使用。 TreeMap和HashMap都是线程不安全的。如果需要同步有两种方法： 可以用 Collections的synchronizedMap方法； 使用 ConcurrentHashMap类，相较于HashTable锁住的是对象整体， ConcurrentHashMap基于lock实现锁分段技术。 首先将Map存放的数据分成一段一段的存储方式，然后给每一段数据分配一把锁，当一个线程占用锁访问其中一个段的数据时，其他段的数据也能被其他线程访问。 ConcurrentHashMap不仅保证了多线程运行环境下的数据访问安全性，而且性能上有长足的提升。 HashMapHashMap 的性能表现非常依赖于哈希码的有效性，请务必掌握 hashCode 和 equals 的一些基本约定，比如 equals 相等，hashCode 一定要相等。 重写了 hashCode 也要重写 equals。 hashCode 需要保持一致性，状态改变返回的哈希值仍然要一致。 equals 的对称、反射、传递等特性。 类似 hashCode 和 equals 的约定，在TreeMap也会有模棱两可的情况出现，自然顺序同样需要符合一个约定，就是 compareTo 的返回值需要和 equals 一致，否则就会出现模棱两可情况。 我们可以分析 TreeMap 的 put 方法实现：1234567891011121314151617public V put(K key, V value) &#123; Entry&lt;K,V&gt; t = … Comparator&lt;? super K&gt; cpr = comparator; if (cpr != null) &#123; do &#123; parent = t; cmp = cpr.compare(key, t.key); if (cmp &lt; 0) t = t.left; else if (cmp &gt; 0) t = t.right; else return t.setValue(value); &#125; while (t != null); &#125; // ...&#125; 重点在于 cmp = cpr.compare(key, t.key); 这行代码，当我不遵守约定时，两个不符合唯一性（equals）要求的对象被当作是同一个（因为，compareTo 返回 0），这会导致歧义的行为表现。 参考 无限循环占用 CPU：https://bugs.java.com/bugdatabase/view_bug.do?bug_id=6423457 hashMap并发安全使用问题：http://mailinator.blogspot.com/2009/06/beautiful-race-condition.html","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"java基础","slug":"java基础","permalink":"http://www.kuanger.top/tags/java基础/"}]},{"title":"Collection集合","slug":"backend/java_基础/Collection集合","date":"2019-01-03T16:00:00.000Z","updated":"2019-01-10T16:01:28.386Z","comments":true,"path":"2019/01/04/backend/java_基础/Collection集合/","link":"","permalink":"http://www.kuanger.top/2019/01/04/backend/java_基础/Collection集合/","excerpt":"集合框架没有 java.util.concurrent 下面的线程安全容器添加进来；也没有列出 Map 容器","text":"集合框架没有 java.util.concurrent 下面的线程安全容器添加进来；也没有列出 Map 容器 线型数据结构的集合Vector、ArrayList、LinkedList均为线型的数据结构。 区别：底层实现方式ArrayList 内部用数组来实现；LinkedList 内部采用双向链表实现；Vector 内部用数组实现。 读写机制 ArrayList 在执行插入元素是超过当前数组预定义的最大值时，数组需要扩容，扩容过程需要调用底层 System.arraycopy()方法 进行大量的数组复制操作，扩容是增加50%的容量； 在删除元素时并不会减少数组的容量（如果需要缩小数组容量，可以调用 trimToSize()方法 ）； 在查找元素时要遍历数组，对于非null的元素采取equals的方式寻找。 LinkedList 在插入元素时，须创建一个新的Entry对象，并更新相应元素的前后元素的引用；在查找元素时，需遍历链表； 在删除元素时，要遍历链表，找到要删除的元素，然后从链表上将此元素删除即可。 Vector与ArrayList仅在插入元素时容量扩充机制不一致。 对于Vector，默认创建一个大小为10的Object数组，并将capacityIncrement设置为0；当插入元素数组大小不够时，如果capacityIncrement大于0，则将Object数组的大小扩大为现有size+capacityIncrement；如果capacityIncrement&lt;=0,则将Object数组的大小扩大为 现有大小的2倍(也就是扩容1倍)。 读写效率 ArrayList对元素的增加和删除都会引起数组的内存分配空间动态发生变化。因此，对其进行插入和删除速度较慢，但检索速度很快。 LinkedList由于基于链表方式存放数据，增加和删除元素的速度较快，但是检索速度较慢。 线程安全性ArrayList、LinkedList为非线程安全；Vector是基于 synchronized 实现的线程安全的ArrayList。 需要注意的是：单线程应尽量使用ArrayList，Vector因为同步会有性能损耗；即使在多线程环境下，我们可以利用 Collections 这个类中为我们提供的 synchronizedList(List list)方法 返回一个线程安全的同步列表对象。 1234//APIstatic &lt;T&gt; List&lt;T&gt; synchronizedList(List&lt;T&gt; list)//举例List list = Collections.synchronizedList(new ArrayList());","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"java基础","slug":"java基础","permalink":"http://www.kuanger.top/tags/java基础/"}]},{"title":"静态代理和动态代理","slug":"backend/java_基础/静态代理和动态代理","date":"2019-01-01T16:00:00.000Z","updated":"2019-01-08T15:31:32.127Z","comments":true,"path":"2019/01/02/backend/java_基础/静态代理和动态代理/","link":"","permalink":"http://www.kuanger.top/2019/01/02/backend/java_基础/静态代理和动态代理/","excerpt":"在某些情况下，一个客户不想或者不能直接引用一个对象，此时可以通过一个称之为 “代理” 的第三者来实现间接引用。代理对象可以在客户端和目标对象之间起到中介的作用，并且可以通过代理对象去掉客户不能看到的内容和服务或者添加客户需要的额外服务。 代理模式(Proxy Pattern) ：给某一个对象提供一个代理，并由代理对象控制对原对象的引用。 按照代理类的创建时期，代理类可分为两种，即动态代理类和静态代理类。 静态代理类：由程序员创建或由特定工具自动生成源代码，再对其编译。在程序运行前，代理类的.class文件就已经存在了。 动态代理类：在程序运行时，运用反射机制动态创建而成。","text":"在某些情况下，一个客户不想或者不能直接引用一个对象，此时可以通过一个称之为 “代理” 的第三者来实现间接引用。代理对象可以在客户端和目标对象之间起到中介的作用，并且可以通过代理对象去掉客户不能看到的内容和服务或者添加客户需要的额外服务。 代理模式(Proxy Pattern) ：给某一个对象提供一个代理，并由代理对象控制对原对象的引用。 按照代理类的创建时期，代理类可分为两种，即动态代理类和静态代理类。 静态代理类：由程序员创建或由特定工具自动生成源代码，再对其编译。在程序运行前，代理类的.class文件就已经存在了。 动态代理类：在程序运行时，运用反射机制动态创建而成。 Java中的静态代理所谓静态代理，就是代理类是由程序员自己编写的，在编译期就确定好了的。 1234567891011public interface HelloSerivice &#123; public void say();&#125;public class HelloSeriviceImpl implements HelloSerivice&#123; @Override public void say() &#123; System.out.println(\"hello world\"); &#125;&#125; 上面的代码比较简单，定义了一个接口和其实现类。这就是代理模式中的目标对象和目标对象的接口。接下类定义代理对象。 1234567891011121314public class HelloSeriviceProxy implements HelloSerivice&#123; private HelloSerivice target; public HelloSeriviceProxy(HelloSerivice target) &#123; this.target = target; &#125; @Override public void say() &#123; System.out.println(\"记录日志\"); target.say(); System.out.println(\"清理数据\"); &#125;&#125; 上面就是一个代理类，他也实现了目标对象的接口，并且扩展了say方法。下面是一个测试类： 123456789101112131415public class Main &#123; @Test public void testProxy()&#123; //目标对象 HelloSerivice target = new HelloSeriviceImpl(); //代理对象 HelloSeriviceProxy proxy = new HelloSeriviceProxy(target); proxy.say(); &#125;&#125;// 输出为下：// 记录日志// hello world// 清理数据 这就是一个简单的静态的代理模式的实现。代理模式中的所有角色（代理对象、目标对象、目标对象的接口）等都是在编译期就确定好的。 静态代理的用途 控制真实对象的访问权限 通过代理对象控制对真实对象的使用权限。 避免创建大对象 通过使用一个代理小对象来代表一个真实的大对象，可以减少系统资源的消耗，对系统进行优化并提高运行速度。 增强真实对象的功能 这个比较简单，通过代理可以在调用真实对象的方法的前后增加额外功能。 Java动态代理Java中，实现动态代理有两种方式： JDK动态代理 ：java.lang.reflect 包中的Proxy类和InvocationHandler 接口 提供了生成动态代理类的能力。 Cglib动态代理 ：Cglib (Code Generation Library ) 是一个第三方代码生成类库，运行时在内存中动态生成一个子类对象从而实现对目标对象功能的 扩展(类继承)。 看 JDK 动态代理的一个简单例子。下面只是加了一句 print，在生产系统中，我们可以轻松扩展类似逻辑进行诊断、限流等。 1234567891011121314151617181920212223242526272829303132public class MyDynamicProxy &#123; public static void main (String[] args) &#123; HelloImpl hello = new HelloImpl(); MyInvocationHandler handler = new MyInvocationHandler(hello); // 构造代码实例 Hello proxyHello = (Hello) Proxy.newProxyInstance(HelloImpl.class.getClassLoader(), HelloImpl.class.getInterfaces(), handler); // 调用代理方法 proxyHello.sayHello(); &#125;&#125;interface Hello &#123; void sayHello();&#125;class HelloImpl implements Hello &#123; @Override public void sayHello() &#123; System.out.println(\"Hello World\"); &#125;&#125; class MyInvocationHandler implements InvocationHandler &#123; private Object target; public MyInvocationHandler(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"Invoking sayHello\"); Object result = method.invoke(target, args); return result; &#125;&#125; 非常简单地实现了动态代理的构建和代理操作。首先，实现对应的 InvocationHandler；然后，以接口 Hello 为纽带，为被调用目标构建代理对象，进而应用程序就可以使用代理对象间接运行调用目标的逻辑，代理为应用插入额外逻辑（这里是 println）提供了便利的入口。 实现动态代理的方式很多，比如 JDK 自身提供的动态代理，就是主要利用了反射机制。还有其他的实现方式，比如利用字节码操作机制，类似 ASM、CGLIB（基于 ASM）、Javassist 等。 举例，常可采用的 JDK提供的动态代理接口InvocationHandler来实现动态代理类。其中invoke方法是该接口定义必须实现的，它完成对真实方法的调用。通过 InvocationHandler接口，所有方法都由该Handler来进行处理，即所有被代理的方法都由InvocationHandler接管实际的处理任务。 此外，我们常可以在invoke方法实现中增加自定义的逻辑实现，实现对被代理类的业务逻辑无侵入。 JDK动态代理和Cglib动态代理的区别 JDK的动态代理有一个限制，就是使用动态代理的对象必须实现一个或多个接口。如果想代理没有实现接口的类，就可以使用CGLIB实现。 Cglib是一个强大的高性能的代码生成包，它可以在运行期扩展Java类与实现Java接口。它广泛的被许多AOP的框架使用，例如Spring AOP和dynaop，为他们提供方法的interception（拦截）。 Cglib包的底层是通过使用一个小而快的字节码处理框架ASM，来转换字节码并生成新的类。不鼓励直接使用ASM，因为它需要你对JVM内部结构包括class文件的格式和指令集都很熟悉。 Cglib与动态代理最大的区别就是： 使用动态代理的对象必须实现一个或多个接口 使用cglib代理的对象则无需实现接口，达到代理类无侵入。 动态代理的用途 Java的动态代理的最主要的用途就是应用在各种框架中。 因为使用动态代理可以很方便的运行期生成代理类，通过代理类可以做很多事情，比如AOP，比如过滤器、拦截器等。 在我们平时使用的框架中，像servlet的filter、包括spring提供的aop以及struts2的拦截器都使用了动态代理功能。 我们日常看到的mybatis分页插件，以及日志拦截、事务拦截、权限拦截这些几乎全部由动态代理的身影。 实际使用场景动态代理应用非常广泛，虽然最初多是因为 RPC 等使用进入我们视线，但是动态代理的使用场景远远不仅如此，它完美符合 Spring AOP 等切面编程。简单来说它可以看作是对 OOP 的一个补充，因为 OOP 对于跨越不同对象或类的分散、纠缠逻辑表现力不够，比如在不同模块的特定阶段做一些事情，类似日志、用户鉴权、全局性异常处理、性能监控，甚至事务处理等，参考下图。 AOP 通过（动态）代理机制可以让开发者从这些繁琐事项中抽身出来，大幅度提高了代码的抽象程度和复用度。 参考 spring使用的代理: https://blog.csdn.net/sinat_36246371/article/details/78158752","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"java基础","slug":"java基础","permalink":"http://www.kuanger.top/tags/java基础/"}]},{"title":"Java反射机制","slug":"backend/java_基础/Java反射机制","date":"2018-12-30T16:00:00.000Z","updated":"2018-12-31T15:08:25.842Z","comments":true,"path":"2018/12/31/backend/java_基础/Java反射机制/","link":"","permalink":"http://www.kuanger.top/2018/12/31/backend/java_基础/Java反射机制/","excerpt":"反射机制是 Java 语言提供的一种基础功能，赋予程序在运行时自省（introspect，官方用语）的能力。通过反射我们可以直接操作类或者对象，比如获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义。","text":"反射机制是 Java 语言提供的一种基础功能，赋予程序在运行时自省（introspect，官方用语）的能力。通过反射我们可以直接操作类或者对象，比如获取某个对象的类定义，获取类声明的属性和方法，调用方法或者构造对象，甚至可以运行时修改类定义。 关于反射反射最大的作用之一就在于我们可以不在编译时知道某个对象的类型，而在运行时通过提供完整的”包名+类名.class”得到。注意：不是在编译时，而是在运行时。利用该机制可以在程序运行过程中对类进行解剖并操作类中的所有成员。 功能： • 在运行时能 判断 任意一个 对象所属的类。 • 在运行时能 构造 任意一个 类的对象。 • 在运行时 判断 任意一个 类所具有的成员变量和方法。 • 在运行时 调用 任意一个 对象的方法。 说大白话就是，利用Java反射机制我们可以加载一个运行时才得知名称的class，获悉其构造方法，并生成其对象实体，能对其fields设值并唤起其methods。 应用场景： 反射技术常用在各类通用框架开发中。 因为为了保证框架的通用性，需要根据配置文件加载不同的对象或类，并调用不同的方法，这个时候就会用到反射——运行时动态加载需要加载的对象。 特点： 由于反射会额外消耗一定的系统资源，因此如果不需要动态地创建一个对象，那么就不需要用反射。另外，反射调用方法时可以忽略权限检查，因此可能会破坏封装性而导致安全问题。 扩展: Accessible反射提供的 AccessibleObject.setAccessible​(boolean flag)。 它的子类也大都重写了这个方法，这里的所谓 accessible 可以理解成修饰成员的 public、protected、private，这意味着我们可以在运行时修改成员访问限制！ setAccessible 的应用场景非常普遍，遍布我们的日常开发、测试、依赖注入等各种框架中。比如，在 O/R Mapping 框架中，我们为一个 Java 实体对象，运行时自动生成 setter、getter 的逻辑，这是加载或者持久化数据非常必要的，框架通常可以利用反射做这个事情，而不需要开发者手动写类似的重复代码。 另一个典型场景就是 绕过 API 访问控制。我们日常开发时可能被迫要调用内部 API 去做些事情，比如，自定义的高性能 NIO 框架需要显式地释放 DirectBuffer，使用反射绕开限制是一种常见办法。 但是，在 Java 9 以后，这个方法的使用可能会存在一些争议，因为 Jigsaw 项目新增的模块化系统，出于强封装性的考虑，对反射访问进行了限制。 Jigsaw 引入了所谓 Open 的概念，只有当被反射操作的模块和指定的包对反射调用者模块 Open，才能使用 setAccessible ；否则，被认为是不合法（illegal）操作。如果我们的实体类是定义在模块里面，我们需要在模块描述符中明确声明： 1234module MyEntities &#123; // Open for reflection opens com.mycorp to java.persistence;&#125; 因为反射机制使用广泛，根据社区讨论，目前，Java 9 仍然保留了兼容 Java 8 的行为，但是 很有可能在未来版本，完全启用前面提到的针对 setAccessible 的限制，即只有当被反射操作的模块和指定的包对反射调用者模块 Open，才能使用 setAccessible，我们可以使用下面参数显式设置。 1--illegal-access=&#123; permit | warn | deny &#125; 反射的操作 反射需要知道的对象 Constructor ：构造方法类，每一个构造方法都是一个Constructor类的对象。 Method ：成员方法类，每一个成员方法都是一个Method类的对象。 Field ：成员变量类，每一个成员变量都是一个Field类的对象 instance ：实例，就是对象 nvoke ：调用，执行 Person类12345678910111213141516171819202122232425262728class Person&#123; private String name; private String age; public Person(String name, String age) &#123; super(); this.name = name; this.age = age; &#125; public Person() &#123; super(); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getAge() &#123; return age; &#125; public void setAge(String age) &#123; this.age = age; &#125; @Override public String toString() &#123; return \"Person [name=\" + name + \", age=\" + age + \"]\"; &#125;&#125; 反射之操作构造方法Class类与构造方法相关的方法 Constructor[] getConstructors() 获得所有的构造方法，返回数组 只包含非private修饰的 Constructor[] getDeclaredConstructors() 获得所有的构造方法，返回数组,包括private修饰的 Constructor getConstructor(Class… parameterTypes) 根据参数类型获得对应的构造方法对象 只能获得非private修饰的 123456789101112131415161718public static void main(String[] args) throws Exception &#123; //获得Person的字节码class对象 Class c=Person.class; //获得无参数构造器 Constructor con=c.getConstructor(); //通过无参数构造器创建对象 Object newInstance = con.newInstance(); System.out.println(newInstance);//Person [name=null, age=null] //获得有参数构造器 Constructor con2=c.getConstructor(String.class,String.class); //通过有参数构造器创建对象 Object newInstance2 = con2.newInstance(\"张三\",\"20\"); System.out.println(newInstance2);//Person [name=张三, age=20]&#125; Constructor getDeclaredConstructor(Class… parameterTypes) 根据参数类型获得对应的构造方法对象，包括private修饰的 public void setAccessible(boolean flag) 暴力反射，设置是否取消权限检查，默认是false flag=true，表示取消权限检查 flag=false，表示不取消权限检查 T newInstance(Object…initargs) Constructor类的成员方法，根据参数实例化创建对象。 12345678910111213141516171819public static void main(String[] args) throws Exception &#123; //把前面的Person的有参数构造方法改为private //获得Person的字节码class对象 Class c=Person.class; //获得有参数构造器 Constructor con2=c.getDeclaredConstructor(String.class,String.class); //暴力反射 /* 如果不改变权限会报出下面异常 java.lang.IllegalAccessException: class com.day_17.demo7.Person with modifiers \"private\" */ con2.setAccessible(true); //通过有参数构造器创建对象 Object newInstance2 = con2.newInstance(\"张三\",\"20\"); System.out.println(newInstance2);//Person [name=张三, age=20]&#125; 反射之操作成员方法Person类 12345class Person&#123; public void run(String a)&#123; System.out.println(a); &#125;&#125; Class类与成员方法相关的方法 public Method[] getMethods() 获得类所有的成员方法对象，包括父类的，返回数组 不包含private修饰 public Method[] getDeclaredMethods() 获得类所有的成员方法对象，不包括父类的，返回数组 包含private修饰 public Method getMethod(String name, Class… parameterTypes) 根据方法名和参数类型获得成员方法对象，不包含private name:方法的名字 parameterTypes:根据方法的参数列表创建的Class对象（多少个数据类型就创建多少个Class） 12345678910111213public static void main(String[] args) throws Exception &#123; //获得Person字节码文件的Class对象 Class c=Person.class; //获得Person的成员方法 Method m=c.getMethod(\"run\",String.class); //通过Class创建一个无参数构造的Person的对象 Object newInstance = c.newInstance(); //执行方法 m.invoke(newInstance,\"hello\");//hello&#125; public Method getDeclaredMethod(String name, Class… parameterTypes) 根据方法名和参数类型获得成员方法对象,包括private的 Method类的成员方法 Object invoke(Object obj, Object… args) 执行方法 obj：调用的是哪个对象的方法。 args：调用方法时要传递的参数 返回调用方法执行的结果 Class类快速创建对象的方法 T newInstance() 前提：该类必须有一个public的无参数构造方法 1234567891011121314151617181920public static void main(String[] args) throws Exception &#123; //把前面的run方法改为private //获得Person字节码文件的Class对象 Class c=Person.class; //获得Person的成员方法 Method m=c.getDeclaredMethod(\"run\",String.class); //暴力反射 /* 如果不改变权限会报出下面异常 java.lang.IllegalAccessException: class com.day_17.demo7.Person with modifiers \"private\" */ m.setAccessible(true); //通过Class创建一个无参数构造的Person的对象 Object newInstance = c.newInstance(); //执行方法 m.invoke(newInstance,\"hello\");//hello&#125; 反射之操作成员变量Person类 12345678class Person&#123; public String name; private String age; @Override public String toString() &#123; return \"Person [name=\" + name + \", age=\" + age + \"]\"; &#125;&#125; Class类与成员变量相关的方法 Field[] getFields(); 获得所有的成员变量，不包含private Field[] getDeclarerdFields(); 获得所有成员变量,包含private Field getField(String name); 根据名称获得对应的成员变量对象，不包含private的 1234567891011121314public static void main(String[] args) throws Exception &#123; //获得Person的字节码Class对象 Class c=Person.class; //获得Person的public成员变量name Field field=c.getField(\"name\"); //通过Class对象创建一个无参数构造的Person对象 Object obj = c.newInstance(); //给对象的name赋值 field.set(obj, \"张三\"); System.out.println(obj);//Person [name=张三, age=0]&#125; Field getDeclaredField(String name); 根据名称获得对应的成员变量对象，包含private的 Field类成员方法 void setXxx(Xxx value); 给对应的成员变量设置为指定的值value xxx就是数据类型， public void set(Object obj, Object value) 给指定对象obj对应的成员变量赋值为value 123456789101112131415161718192021public static void main(String[] args) throws Exception &#123; //获得Person的字节码Class对象 Class c=Person.class; //获得Person的private成员变量age Field field=c.getDeclaredField(\"age\"); //暴力反射 /* 如果不改变权限会报出下面异常 java.lang.IllegalAccessException: class com.day_17.demo7.Person with modifiers \"private\" */ field.setAccessible(true); //通过Class对象创建一个无参数构造的Person对象 Object obj = c.newInstance(); //给对象的name赋值 field.setInt(obj, 20); System.out.println(obj);//Person [name=null, age=20]&#125; 案例1ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); 在这个泛型为 Integer 的 ArrayList 中存放一个 String 类型的对象。 泛型只是在编译器起作用，在字节码表中类型还是Object，运行的时候才变成泛型规定的类型 12345678910111213141516171819202122232425public static void main(String[] args) throws Exception &#123; //创建一个ArrayList对象 ArrayList&lt;Integer&gt; list=new ArrayList&lt;&gt;(); //添加Integer元素 list.add(11); list.add(2); //获得list的class对象 Class c=list.getClass(); //通过class生成一个新的ArrayList对象 Object newInstance = c.newInstance(); //获得ArrayList的add方法 Method m=c.getMethod(\"add\",Object.class); //添加元素到newInstance集合中 m.invoke(newInstance, \"newInstance\"); //添加元素到list集合中 m.invoke(list, \"list\"); System.out.println(list);//[11, 2, list] System.out.println(newInstance);//[newInstance]&#125;","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"java基础","slug":"java基础","permalink":"http://www.kuanger.top/tags/java基础/"}]},{"title":"fail-fast和fail-safe","slug":"backend/java_基础/fail-fast和fail-safe","date":"2018-12-29T16:00:01.000Z","updated":"2018-12-30T13:13:47.018Z","comments":true,"path":"2018/12/30/backend/java_基础/fail-fast和fail-safe/","link":"","permalink":"http://www.kuanger.top/2018/12/30/backend/java_基础/fail-fast和fail-safe/","excerpt":"fail-fast ( 快速失败 ) 在使用迭代器遍历一个集合对象时,比如增强for,如果遍历过程中对集合对象的内容进行了修改(增删改),会抛出 ConcurrentModificationException 异常.","text":"fail-fast ( 快速失败 ) 在使用迭代器遍历一个集合对象时,比如增强for,如果遍历过程中对集合对象的内容进行了修改(增删改),会抛出 ConcurrentModificationException 异常. 查看ArrayList源代码，在next方法执行的时候，会执行checkForComodification()方法12345678910111213141516171819@SuppressWarnings(&quot;unchecked&quot;) public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i]; &#125; //...............省略.............final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); &#125; 原理: 迭代器在遍历时直接访问集合中的内容,并且在遍历过程中使用一个modCount变量, 集合中在被遍历期间如果内容发生变化,就会改变modCount的值, 每当迭代器使用 hashNext()/next()遍历下一个元素之前,都会检测modCount变量和expectedmodCount值是否相等, 如果相等就返回遍历,否则抛出异常,终止遍历. 举例 12345//会抛出ConcurrentModificationException异常for(Person person : Persons)&#123; if(person.getId()==2) student.remove(person);&#125; 注意这里异常的抛出条件时检测到modCount = expectedmodCount 这个条件. 如果集合发生变化时修改modCount值, 刚好有设置为了expectedmodCount值, 则异常不会抛出.(比如删除了数据,再添加一条数据)1234567//不会抛出ConcurrentModificationException异常for(Person person : Persons)&#123; if(person.getId()==2)&#123; Persons.remove(person); Persons.add(new Person()); &#125;&#125; 所以不能依赖于这个异常是否抛出而进行并发操作的编程, 这个异常只建议检测并发修改的bug. 使用场景 :java.util包下的集合类都是快速失败机制的, 不能在多线程下发生并发修改(迭代过程中被修改). fail-safe ( 安全失败 )采用安全失败机制的集合容器,在遍历时不是直接在集合内容上访问的,而是先copy原有集合内容,在拷贝的集合上进行遍历. 原理: 由于迭代时是对原集合的拷贝的值进行遍历,所以在遍历过程中对原集合所作的修改并不能被迭代器检测到,所以不会出发ConcurrentModificationException 缺点: 基于拷贝内容的优点是避免了ConcurrentModificationException,但同样地, 迭代器并不能访问到修改后的内容 (简单来说就是, 迭代器遍历的是开始遍历那一刻拿到的集合拷贝,在遍历期间原集合发生的修改迭代器是不知道的) 使用场景:java.util.concurrent包下的容器都是安全失败的,可以在多线程下并发使用,并发修改.","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"java基础","slug":"java基础","permalink":"http://www.kuanger.top/tags/java基础/"}]},{"title":"值传递和引用传递","slug":"backend/java_基础/值传递和引用传递","date":"2018-12-29T16:00:00.000Z","updated":"2018-12-30T13:13:47.019Z","comments":true,"path":"2018/12/30/backend/java_基础/值传递和引用传递/","link":"","permalink":"http://www.kuanger.top/2018/12/30/backend/java_基础/值传递和引用传递/","excerpt":"值传递（pass by value） 是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。 引用传递（pass by reference） 是指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。","text":"值传递（pass by value） 是指在调用函数时将实际参数复制一份传递到函数中，这样在函数中如果对参数进行修改，将不会影响到实际参数。 引用传递（pass by reference） 是指在调用函数时将实际参数的地址直接传递到函数中，那么在函数中对参数所进行的修改，将影响到实际参数。 口述先说基本类型和引用类型 基本类型创建的时候,他的值都分别会放在栈中和常量池中的,而引用类型的话他的值是存放在堆内存中,然后栈存放的只是这个对象的地址值 其实所以值传递,其实很多人都会有误区都认为传递的参数如果是普通类型，那就是值传递，如果是对象，那就是引用传递, 并不是这样的,其实如果把值传递和引用传递放在C语言中,那就地址传递,其实Java也是可以这样理解的, 传递也是地址值, 在调用函数的时候,他会把实际参数的地址值拷贝一份传递到函数中 如果这个地址的实际参数是 在栈中 的话,他会 直接拷贝值 ,所以函数内部对参数进行操作是不会对实际参数产生影响的, 如果拷贝的原 值在堆中的地址 ,他会 根据该地址值去堆中对应的对象 ,再进行操作,所以测函数内对值的操作是影响实际参数的. 其实不管是值传递还是引用传递,其实都是一种求值策略,在求值策略中,叫做按共享传递, 所以简单点的来说, java的传递是值传递,而这个值是地址值,可以是栈中的值或堆中对象的引用罢了 参考文章 : http://mp.weixin.qq.com/s/F7Niaa7nD1tLApCEGKAj4A","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"java基础","slug":"java基础","permalink":"http://www.kuanger.top/tags/java基础/"}]},{"title":"String、StringBuffer、StringBuilder有什么区别","slug":"backend/java_基础/String、StringBuffer、StringBuilder有什么区别","date":"2018-12-29T16:00:00.000Z","updated":"2018-12-29T16:05:06.672Z","comments":true,"path":"2018/12/30/backend/java_基础/String、StringBuffer、StringBuilder有什么区别/","link":"","permalink":"http://www.kuanger.top/2018/12/30/backend/java_基础/String、StringBuffer、StringBuilder有什么区别/","excerpt":"典型回答 String 是 Java 语言非常基础和重要的类，提供了构造和管理字符串的各种基本逻辑。它是典型的 Immutable 类，被声明成为 final class，所有属性也都是 final 的。也由于它的不可变性，类似拼接、裁剪字符串等动作，都会产生新的 String 对象。由于字符串操作的普遍性，所以相关操作的效率往往对应用性能有明显影响。 StringBuffer 是为解决上面提到拼接产生太多中间对象的问题而提供的一个类，我们可以用 append 或者 add 方法，把字符串添加到已有序列的末尾或者指定位置。StringBuffer 本质是一个线程安全的可修改字符序列，它保证了线程安全，也随之带来了额外的性能开销，线程是安全的。 StringBuilder 是 Java 1.5 中新增的，在能力上和 StringBuffer 没有本质区别，但是它去掉了线程安全的部分，有效减小了开销，是绝大部分情况下进行字符串拼接的首选。","text":"典型回答 String 是 Java 语言非常基础和重要的类，提供了构造和管理字符串的各种基本逻辑。它是典型的 Immutable 类，被声明成为 final class，所有属性也都是 final 的。也由于它的不可变性，类似拼接、裁剪字符串等动作，都会产生新的 String 对象。由于字符串操作的普遍性，所以相关操作的效率往往对应用性能有明显影响。 StringBuffer 是为解决上面提到拼接产生太多中间对象的问题而提供的一个类，我们可以用 append 或者 add 方法，把字符串添加到已有序列的末尾或者指定位置。StringBuffer 本质是一个线程安全的可修改字符序列，它保证了线程安全，也随之带来了额外的性能开销，线程是安全的。 StringBuilder 是 Java 1.5 中新增的，在能力上和 StringBuffer 没有本质区别，但是它去掉了线程安全的部分，有效减小了开销，是绝大部分情况下进行字符串拼接的首选。 StringString的创建机理由于String在Java世界中使用过于频繁，Java为了避免在一个系统中产生大量的String对象，引入了字符串常量池。 其运行机制是： 创建一个字符串时，首先检查池中是否有值相同的字符串对象，如果有则不需要创建直接从池中刚查找到的对象引用； 如果没有则新建字符串对象，返回对象引用，并且将新创建的对象放入池中。 但是，通过new方法创建的String对象是不检查字符串池的，而是直接在堆区或栈区创建一个新的对象，也不会把对象放入池中。上述原则只适用于通过直接量给String对象引用赋值的情况。 举例： 12String str1 = \"123\"; //通过直接量赋值方式，放入字符串常量池String str2 = new String(“123”);//通过new方式赋值方式，不放入字符串常量池 注意：String提供了 intern() 方法。调用该方法时，如果常量池中包括了一个等于此String对象的字符串（由equals方法确定），则返回池中的字符串。否则，将此String对象添加到池中，并且返回此池中对象的引用。 == 的比较 12345678910@Testpublic void test()&#123; String a = \"123\"; String b = \"123\"; String c = new String(\"123\"); System.out.println(a==b);//true System.out.println(a==c);//false String d = c.intern();//把堆内存的值放进常量池返回一个string System.out.println(a==d);//true&#125; String的特性 不可变 (Immutable)。是指String对象一旦生成，则不能再对它进行改变。不可变的主要作用在于当一个对象需要被多线程共享，并且访问频繁时，可以省略同步和锁等待的时间，从而大幅度提高系统性能。不可变模式是一个可以提高多线程程序的性能，降低多线程程序复杂度的设计模式。 针对常量池的优化。当2个String对象拥有相同的值时，他们只引用常量池中的同一个拷贝。当同一个字符串反复出现时，这个技术可以大幅度节省内存空间。 StringBuffer/StringBuilder 为了实现修改字符序列的目的，StringBuffer 和 StringBuilder 底层都是利用可修改的（char，JDK 9 以后是 byte）数组，二者都继承了 AbstractStringBuilder，里面包含了基本操作，区别仅在于最终的方法是否加了 synchronized。 另外，这个内部数组应该创建成多大的呢？如果太小，拼接的时候可能要重新创建足够大的数组；如果太大，又会浪费空间。目前的实现是，构建时初始字符串长度加 16（这意味着，如果没有构建对象时输入最初的字符串，那么初始值就是 16）。 我们如果确定拼接会发生非常多次，而且大概是可预计的，那么最好就可以指定合适的大小，避免很多次扩容的开销。扩容会产生多重开销，因为要抛弃原有数组，创建新的（可以简单认为是倍数）数组，还要进行 arraycopy。 全部拼接操作是应该都用 StringBuilder 实现吗？在没有线程安全问题的情况下，全部拼接操作是应该都用 StringBuilder 实现吗？毕竟这样书写的代码，还是要多敲很多字的，可读性也不理想，下面的对比非常明显。 1234String strByBuilder = newStringBuilder().append(\"aa\").append(\"bb\").append(\"cc\").append(\"dd\").toString(); String strByConcat = \"aa\" + \"bb\" + \"cc\" + \"dd\"; 其实，在通常情况下，没有必要过于担心，要相信 Java 还是非常智能的。我们来做个实验，把下面一段代码，利用不同版本的 JDK 编译，然后再反编译，例如： 123456public class StringConcat &#123; public static void main(String[] args) &#123; String myStr = \"aa\" + \"bb\" + \"cc\" + \"dd\"; System.out.println(\"My String:\" + myStr); &#125; &#125; 先编译再反编译，比如使用不同版本的 JDK： 12$&#123;JAVA_HOME&#125;/bin/javac StringConcat.java$&#123;JAVA_HOME&#125;/bin/javap -v StringConcat.class JDK 8 的输出片段是： 12345678910110: ldc #2 // String aabbccdd2: astore_13: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream;6: new #4 // class java/lang/StringBuilder9: dup10: invokespecial #5 // Method java/lang/StringBuilder.\"&lt;init&gt;\":()V13: ldc #6 // String My String:15: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;18: aload_119: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder;22: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 而在 JDK 9 中，反编译的结果就非常简单了，片段是： 123450: ldc #2 // String aabbccdd2: astore_13: getstatic #3 // Field java/lang/System.out:Ljava/io/PrintStream;6: aload_17: invokedynamic #4, 0 // InvokeDynamic #0:makeConcatWithConstants:(Ljava/lang/String;)Ljava/lang/String; 在 JDK 8 中，字符串拼接操作会自动被 javac 转换为 StringBuilder 操作 而在 JDK 9 里面则是因为 Java 9 为了更加统一字符串操作优化，提供了 StringConcatFactory，作为一个统一的入口。 javac 自动生成的代码，虽然未必是最优化的，但普通场景也足够了，你可以酌情选择。 字符串缓存我们粗略统计过，把常见应用进行 堆转储（Dump Heap），然后分析对象组成，会发现平均 25% 的对象是字符串，并且其中约半数是重复的。如果能避免创建重复字符串，可以有效降低内存消耗和对象创建开销。 提供 intern() 方法把字符串放进常量池缓存 String 在 Java 6 以后提供了 intern() 方法，目的是提示 JVM 把相应字符串缓存起来，以备重复使用。在我们创建字符串对象并调用 intern() 方法的时候，如果已经有缓存的字符串，就会返回缓存里的实例，否则将其缓存起来。一般来说，JVM 会将所有的类似“abc”这样的文本字符串，或者字符串常量之类缓存起来。 一般使用 Java 6 这种历史版本，并不推荐大量使用 intern，因为被缓存的字符串是存在所谓 PermGen 里的，也就是 臭名昭著的“永久代”，这个空间是很有限的，也基本不会被 FullGC 之外的垃圾收集照顾到。所以，如果使用不当，OOM 就会光顾。 针对intern的勉强解决和问题 在后续版本中，这个缓存被放置在堆中，这样就极大避免了永久代占满的问题，甚至永久代在 JDK 8 中被 MetaSpace（元数据区）替代了。 而且，默认缓存大小也在不断地扩大中，从最初的 1009，到 7u40 以后被修改为 60013。你可以使用下面的参数直接打印具体数字，可以拿自己的 JDK 立刻试验一下。 1-XX:+PrintStringTableStatistics 你也可以使用下面的 JVM 参数手动调整大小，但是绝大部分情况下并不需要调整，除非你确定它的大小已经影响了操作效率。 1-XX:StringTableSize=N 问题: Intern 是一种显式地排重机制，但是它也有一定的副作用，因为需要开发者写代码时明确调用，一是不方便，每一个都显式调用是非常麻烦的；另外就是我们很难保证效率，应用开发阶段很难清楚地预计字符串的重复情况，有人认为这是一种污染代码的实践。 更好的解决使用G1 GC 下的字符串排重在 Oracle JDK 8u20 之后，推出了一个新的特性，也就是 G1 GC 下的字符串排重。它是通过将相同数据的字符串指向同一份数据来做到的，是 JVM 底层的改变，并不需要 Java 类库做什么修改。 注意这个功能目前是默认关闭的，你需要使用下面参数开启，并且记得指定使用 G1 GC： 1-XX:+UseStringDeduplication 前面说到的几个方面，只是 Java 底层对字符串各种优化的一角，在运行时，字符串的一些基础操作会直接利用 JVM 内部的 Intrinsic 机制，往往运行的就是特殊优化的本地代码，而根本就不是 Java 代码生成的字节码。 Intrinsic 可以简单理解为，是一种利用 native 方式 hard-coded 的逻辑，算是一种特别的内联，很多优化还是需要直接使用特定的 CPU 指令，具体可以看相关源码，搜索“string”以查找相关 Intrinsic 定义。当然，你也可以在启动实验应用时，使用下面参数，了解 intrinsic 发生的状态。 123456-XX:+PrintCompilation -XX:+UnlockDiagnosticVMOptions -XX:+PrintInlining // 样例输出片段 180 3 3 java.lang.String::charAt (25 bytes) @ 1 java.lang.String::isLatin1 (19 bytes) ... @ 7 java.lang.StringUTF16::getChar (60 bytes) intrinsic 可以看出，仅仅是字符串一个实现，就需要 Java 平台工程师和科学家付出如此大且默默无闻的努力，我们得到的很多便利都是来源于此。 String自身的演化对于 Java 的字符串，在历史版本中，它是使用 char 数组来存数据的，这样非常直接。但是 Java 中的 char 是两个 bytes 大小，拉丁语系语言的字符，根本就不需要太宽的 char，这样无区别的实现就造成了一定的浪费。密度是编程语言平台永恒的话题，因为归根结底绝大部分任务是要来操作数据的。 在 Java 9 中，我们引入了 Compact Strings 的设计，对字符串进行了大刀阔斧的改进。将数据存储方式从 char 数组，改变为一个 byte 数组加上一个标识编码的所谓 coder，并且将相关字符串操作类都进行了修改。另外，所有相关的 Intrinsic 之类也都进行了重写，以保证没有任何性能损失。 虽然底层实现发生了这么大的改变，但是 Java 字符串的行为并没有任何大的变化，所以这个特性对于绝大部分应用来说是透明的，绝大部分情况不需要修改已有代码。 理论上的问题: 在极端情况下，字符串也出现了一些能力退化，比如最大字符串的大小。你可以思考下，原来 char 数组的实现，字符串的最大长度就是数组本身的长度限制，但是替换成 byte 数组，同样数组长度下，存储能力是退化了一倍的！还好这是存在于理论中的极限，还没有发现现实应用受此影响。 byte是字节数据类型、有符号型的、占1个字节、大小范围为-128——127 char是字符数据类型、无符号型的、占2个字节(unicode码)、大小范围为0-65535 在通用的性能测试和产品实验中，我们能非常明显地看到紧凑字符串带来的优势，即更小的内存占用、更快的操作速度。","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"java基础","slug":"java基础","permalink":"http://www.kuanger.top/tags/java基础/"},{"name":"string","slug":"string","permalink":"http://www.kuanger.top/tags/string/"}]},{"title":"强引用、软引用、弱引用、幻象引用有什么区别","slug":"backend/java_基础/强引用、软引用、弱引用、幻象引用有什么区别","date":"2018-12-28T16:01:00.000Z","updated":"2018-12-29T16:00:37.878Z","comments":true,"path":"2018/12/29/backend/java_基础/强引用、软引用、弱引用、幻象引用有什么区别/","link":"","permalink":"http://www.kuanger.top/2018/12/29/backend/java_基础/强引用、软引用、弱引用、幻象引用有什么区别/","excerpt":"典型回答不同的引用类型，分别有强引用（“Strong” Reference）、软引用（SoftReference）、弱引用（WeakReference）、幻象引用（PhantomReference），主要体现的是 对象不同的可达性（reachable）状态和对垃圾收集的影响。","text":"典型回答不同的引用类型，分别有强引用（“Strong” Reference）、软引用（SoftReference）、弱引用（WeakReference）、幻象引用（PhantomReference），主要体现的是 对象不同的可达性（reachable）状态和对垃圾收集的影响。 所谓 强引用（“Strong” Reference），就是我们最常见的普通对象引用，只要还有强引用指向一个对象，就能表明对象还“活着”，垃圾收集器不会碰这种对象。对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为 null，就是可以被垃圾收集的了，当然具体回收时机还是要看垃圾收集策略。 应用场景：项目中到处都是。12Object obj = new Object();obj.equels(new Object());//可直接通过obj取得对应的对象 软引用（SoftReference），是一种相对强引用弱化一些的引用，可以让对象豁免一些垃圾收集，只有当 JVM 认为内存不足时，才会去试图回收软引用指向的对象。JVM 会确保在抛出 OutOfMemoryError 之前，清理软引用指向的对象。软引用通常用来实现内存敏感的缓存，如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。 后续，我们可以调用ReferenceQueue的poll()方法来检查是否有它所关心的对象被回收。如果队列为空，将返回一个null,否则该方法返回队列中前面的一个Reference对象。 应用场景：软引用通常用来实现内存敏感的缓存。 如果还有空闲内存，就可以暂时保留缓存，当内存不足时清理掉，这样就保证了使用缓存的同时，不会耗尽内存。（图片缓存框架中，“内存缓存”中的图片是以这种引用来保存） 1234Object obj = new Object();SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj);obj = null;sf.get();//有时候会返回null 弱引用（WeakReference）并不能使对象豁免垃圾收集，仅仅是提供一种访问在弱引用状态下对象的途径。这就可以用来构建一种没有特定约束的关系，比如，维护一种非强制性的映射关系，如果试图获取时对象还在，就使用它，否则重现实例化。它同样是很多缓存实现的选择。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。由于垃圾回收器是一个优先级很低的线程，因此不一定会很快回收弱引用的对象。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 应用场景：弱应用同样可用于内存敏感的缓存。12345Object obj = new Object();WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);obj = null;wf.get();//有时候会返回nullwf.isEnQueued();//返回是否被垃圾回收器标记为即将回收的垃圾 对于 幻象引用（PhantomReference），有时候也翻译成虚引用，你不能通过它访问对象。幻象引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制，比如，通常用来做所谓的 Post-Mortem 清理机制，在Java 平台自身 Cleaner 机制等，也有人利用幻象引用监控对象的创建和销毁。 他通过 PhantomReference类 来实现。无法通过虚引用访问对象的任何属性或函数。幻象引用仅仅是提供了一种确保对象被 finalize 以后，做某些事情的机制。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收器回收。虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。 12ReferenceQueue queue = new ReferenceQueue ();PhantomReference pr = new PhantomReference (object, queue); 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取一些程序行动。 应用场景：可用来跟踪对象被垃圾回收器回收的活动，当一个虚引用关联的对象被垃圾收集器回收之前会收到一条系统通知。 12345Object obj = new Object();PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj);obj=null;pf.get();//永远返回nullpf.isEnQueued();//返回是否从内存中已经删除 对象可达性状态流转分析这是 Java 定义的不同可达性级别（reachability level），简单总结了对象生命周期和不同可达性状态，以及不同状态可能的改变关系，可能未必 100% 严谨，但足够观察其变化。 强可达（Strongly Reachable），就是当一个对象可以有一个或多个线程可以不通过各种引用访问到的情况。比如，我们新创建一个对象，那么创建它的线程对它就是强可达。 软可达（Softly Reachable），就是当我们只能通过软引用才能访问到对象的状态。 弱可达（Weakly Reachable），类似前面提到的，就是无法通过强引用或者软引用访问，只能通过弱引用访问时的状态。这是十分临近 finalize 状态的时机，当弱引用被清除的时候，就符合 finalize 的条件了。 幻象可达（Phantom Reachable），上面流程图已经很直观了，就是没有强、软、弱引用关联，并且 finalize 过了，只有幻象引用指向这个对象的时候。 当然，还有一个最后的状态，就是不可达（unreachable），意味着对象可以被清除了。 判断对象可达性，是 JVM 垃圾收集器决定如何处理对象的一部分考虑。 所有引用类型，都是抽象类 java.lang.ref.Reference 的子类，你可能注意到它提供了 get() 方法： 除了幻象引用（因为 get 永远返回 null），如果对象还没有被销毁，都可以通过 get 方法获取原有对象。这意味着，利用软引用和弱引用，我们可以将访问到的对象，重新指向强引用，也就是人为的改变了对象的可达性状态！这所以在上面图里有些地方画了双向箭头。 注意： 如果我们错误的保持了强引用（比如，赋值给了 static 变量），那么对象可能就没有机会变回类似弱引用的可达性状态了，就会产生内存泄漏。所以，检查弱引用指向对象是否被垃圾收集，也是诊断是否有特定内存泄漏的一个思路，如果我们的框架使用到弱引用又怀疑有内存泄漏，就可以从这个角度检查。 引用队列（ReferenceQueue）使用谈到各种引用的编程，就必然要提到引用队列。我们在创建各种引用并关联到响应对象时，可以选择是否需要关联引用队列，JVM 会在特定时机将引用 enqueue 到队列里，我们可以从队列里获取引用（remove 方法在这里实际是有获取的意思）进行相关后续逻辑。尤其是幻象引用，get 方法只返回 null，如果再不指定引用队列，基本就没有意义了。看看下面的示例代码。利用引用队列，我们可以在对象处于相应状态时（对于幻象引用，就是前面说的被 finalize 了，处于幻象可达状态），执行后期处理逻辑。 1234567891011121314Object counter = new Object();ReferenceQueue refQueue = new ReferenceQueue&lt;&gt;();PhantomReference&lt;Object&gt; p = new PhantomReference&lt;&gt;(counter, refQueue);counter = null;System.gc();try &#123; // Remove 是一个阻塞方法，可以指定 timeout，或者选择一直阻塞 Reference&lt;Object&gt; ref = refQueue.remove(1000L); if (ref != null) &#123; // do something &#125;&#125; catch (InterruptedException e) &#123; // Handle it&#125; Make a logo 显式地影响软引用垃圾收集前面泛泛提到了引用对垃圾收集的影响，尤其是软引用，到底 JVM 内部是怎么处理它的，其实并不是非常明确。那么我们能不能使用什么方法来影响软引用的垃圾收集呢？ 答案是有的。软引用通常会在最后一次引用后，还能保持一段时间，默认值是根据堆剩余空间计算的（以 M bytes 为单位）。从 Java 1.3.1 开始，提供了 -XX:SoftRefLRUPolicyMSPerMB 参数，我们可以以毫秒（milliseconds）为单位设置。比如，下面这个示例就是设置为 3 秒（3000 毫秒）。 1-XX:SoftRefLRUPolicyMSPerMB=3000 这个剩余空间，其实会受不同 JVM 模式影响，对于 Client 模式，比如通常的 Windows 32 bit JDK，剩余空间是计算当前堆里空闲的大小，所以更加倾向于回收；而对于 server 模式 JVM，则是根据 -Xmx 指定的最大值来计算。 本质上，这个行为还是个黑盒，取决于 JVM 实现，即使是上面提到的参数，在新版的 JDK 上也未必有效，另外 Client 模式的 JDK 已经逐步退出历史舞台。所以在我们应用时，可以参考类似设置，但不要过于依赖它。 诊断 JVM 引用情况如果你怀疑应用存在引用（或 finalize）导致的回收问题，可以有很多工具或者选项可供选择，比如 HotSpot JVM 自身便提供了明确的选项（PrintReferenceGC）去获取相关信息，我指定了下面选项去使用 JDK 8 运行一个样例应用： 1-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintReferenceGC 这是 JDK 8 使用 ParrallelGC 收集的垃圾收集日志，各种引用数量非常清晰。 10.403: [GC (Allocation Failure) 0.871: [SoftReference, 0 refs, 0.0000393 secs]0.871: [WeakReference, 8 refs, 0.0000138 secs]0.871: [FinalReference, 4 refs, 0.0000094 secs]0.871: [PhantomReference, 0 refs, 0 refs, 0.0000085 secs]0.871: [JNI Weak Reference, 0.0000071 secs][PSYoungGen: 76272K-&gt;10720K(141824K)] 128286K-&gt;128422K(316928K), 0.4683919 secs] [Times: user=1.17 sys=0.03, real=0.47 secs] 注意：JDK 9 对 JVM 和垃圾收集日志进行了广泛的重构，类似 PrintGCTimeStamps 和 PrintReferenceGC 已经不再存在，我在专栏后面的垃圾收集主题里会更加系统的阐述。 Reachability Fence除了我前面介绍的几种基本引用类型，我们也可以通过底层 API 来达到强引用的效果，这就是所谓的设置reachability fence。 为什么需要这种机制呢？考虑一下这样的场景，按照 Java 语言规范，如果一个对象没有指向强引用，就符合垃圾收集的标准，有些时候，对象本身并没有强引用，但是也许它的部分属性还在被使用，这样就导致诡异的问题，所以我们需要一个方法，在没有强引用情况下，通知 JVM 对象是在被使用的。说起来有点绕，我们来看看 Java 9 中提供的案例。 12345678910111213141516171819202122232425class Resource &#123; private static ExternalResource[] externalResourceArray = ... int myIndex; Resource(...) &#123; myIndex = ... externalResourceArray[myIndex] = ...; ... &#125; protected void finalize() &#123; externalResourceArray[myIndex] = null; ... &#125; public void action() &#123; try &#123; // 需要被保护的代码 int i = myIndex; Resource.update(externalResourceArray[i]); &#125; finally &#123; // 调用 reachbilityFence，明确保障对象 strongly reachable Reference.reachabilityFence(this); &#125; &#125; private static void update(ExternalResource ext) &#123; ext.status = ...; &#125;&#125; 方法 action 的执行，依赖于对象的部分属性，所以被特定保护了起来。否则，如果我们在代码中像下面这样调用，那么就可能会出现困扰，因为没有强引用指向我们创建出来的 Resource 对象，JVM 对它进行 finalize 操作是完全合法的。 1new Resource().action() 类似的书写结构，在异步编程中似乎是很普遍的，因为异步编程中往往不会用传统的“执行 -&gt; 返回 -&gt; 使用”的结构。 在 Java 9 之前，实现类似类似功能相对比较繁琐，有的时候需要采取一些比较隐晦的小技巧。幸好，java.lang.ref.Reference 给我们提供了新方法，它是 JEP 193: Variable Handles 的一部分，将 Java 平台底层的一些能力暴露出来： 1static void reachabilityFence(Object ref) 在 JDK 源码中，reachabilityFence 大多使用在 Executors 或者类似新的 HTTP/2 客户端代码中，大部分都是异步调用的情况。编程中，可以按照上面这个例子，将需要 reachability 保障的代码段利用 try-finally 包围起来，在 finally 里明确声明对象强可达。","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"java基础","slug":"java基础","permalink":"http://www.kuanger.top/tags/java基础/"}]},{"title":"谈谈 final、finally、 finalize 有什么不同","slug":"backend/java_基础/谈谈 final、finally、 finalize 有什么不同","date":"2018-12-28T16:00:00.000Z","updated":"2018-12-29T13:59:57.804Z","comments":true,"path":"2018/12/29/backend/java_基础/谈谈 final、finally、 finalize 有什么不同/","link":"","permalink":"http://www.kuanger.top/2018/12/29/backend/java_基础/谈谈 final、finally、 finalize 有什么不同/","excerpt":"典型回答 final 可以用来修饰类、方法、变量，分别有不同的意义，final 修饰的 class 代表不可以继承扩展，final 的变量是不可以修改的，而 final 的方法也是不可以重写的（override）。 finally则是 Java 保证重点代码一定要被执行的一种机制。我们可以使用 try-finally 或者 try-catch-finally 来进行类似关闭 JDBC 连接、保证 unlock 锁等动作。 finalize 是基础类 java.lang.Object 的一个方法，它的设计目的是保证对象在被垃圾收集前完成特定资源的回收。finalize 机制现在已经不推荐使用，并且在 JDK 9 开始被标记为 deprecated。","text":"典型回答 final 可以用来修饰类、方法、变量，分别有不同的意义，final 修饰的 class 代表不可以继承扩展，final 的变量是不可以修改的，而 final 的方法也是不可以重写的（override）。 finally则是 Java 保证重点代码一定要被执行的一种机制。我们可以使用 try-finally 或者 try-catch-finally 来进行类似关闭 JDBC 连接、保证 unlock 锁等动作。 finalize 是基础类 java.lang.Object 的一个方法，它的设计目的是保证对象在被垃圾收集前完成特定资源的回收。finalize 机制现在已经不推荐使用，并且在 JDK 9 开始被标记为 deprecated。 语法、并发、性能、生命周期等final 我们可以将方法或者类声明为 final，这样就可以明确告知别人，这些行为是不许修改的。 如果你关注过 Java 核心类库的定义或源码， 有没有发现 java.lang 包下面的很多类，相当一部分都被声明成为 final class？在第三方类库的一些基础类中同样如此，这可以有效避免 API 使用者更改基础功能，某种程度上，这是保证平台安全的必要手段。 使用 final 修饰参数或者变量，也可以清楚地避免意外赋值导致的编程错误，甚至，有人明确推荐将所有方法参数、本地变量、成员变量声明成 final。 final 变量产生了某种程度的 不可变（immutable） 的效果，所以，可以用于保护只读数据，尤其是在并发编程中，因为明确地不能再赋值 final 变量，有利于减少额外的同步开销，也可以省去一些防御性拷贝的必要。 final 也许会有性能的好处，比如，利用 final 可能有助于 JVM 将方法进行内联，可以改善编译器进行条件编译的能力等等。坦白说，很多类似的结论都是基于假设得出的，比如现代高性能 JVM（如 HotSpot）判断内联未必依赖 final 的提示，要相信 JVM 还是非常智能的。 对于final的不可变（immutable）做个说明 12345final List&lt;String&gt; strList = new ArrayList&lt;&gt;();strList.add(\"Hello\");strList.add(\"world\"); List&lt;String&gt; unmodifiableStrList = List.of(\"hello\", \"world\");unmodifiableStrList.add(\"again\"); final 只能约束 strList 这个引用不可以被赋值，但是 strList 对象行为不被 final 影响，添加元素等操作是完全正常的。如果我们真的希望对象本身是不可变的，那么需要相应的类支持不可变的行为。在上面这个例子中，List.of 方法创建的本身就是不可变 List，最后那句 add 是会在运行时抛出异常的。 还有一个地方值得说明，当 内部类 (inner clas) 访问局部变量的时候，是需要用final声明变量的，因为Java inner class实际会copy一份，不是去直接使用局部变量，final可以防止出现数据一致性问题。 finally虽然说正常情况下finally是可以保证重点代码一定要被执行的一种机制，但他也有不执行的时候： 程序退出 123456789@Test public void client() throws Exception&#123; try &#123; // do something System.exit(1); &#125; finally&#123; System.out.println(\"Print from finally\"); &#125; &#125; system.exit（0） : 正常退出，程序正常执行结束退出 system.exit （1） : 是非正常退出，就是说无论程序正在执行与否，都退出 无限循环 1234567891011@Test public void client() throws Exception&#123; try &#123; // do something while (true)&#123; System.out.println(\"loop\"); &#125; &#125; finally&#123; System.out.println(\"Print from finally\"); &#125; &#125; 线程被杀死 当执行 try，finally 的线程被杀死时。finally 也无法执行。 所以 不要在 finally 中使用 return 语句。finally 总是执行，除非程序或者线程被中断。 finalize 对于 finalize，我们要明确它是不推荐使用的，业界实践一再证明它不是个好的办法，在 Java 9 中，甚至明确将 Object.finalize()标记为 deprecated ！如果没有特别的原因，不要实现 finalize方法，也不要指望利用它来进行资源回收。 为什么呢？简单说，你无法保证 finalize 什么时候执行，执行的是否符合预期。使用不当会影响性能，导致程序死锁、挂起等。 通常来说，利用上面的提到的 try-with-resources 或者 try-finally 机制，是非常好的 回收资源的办法。如果确实需要额外处理，可以考虑 Java 提供的 Cleaner 机制 或者其他替代方法。 finalize 的执行是和垃圾收集关联在一起的，一旦实现了非空的 finalize 方法，就会导致相应对象回收呈现数量级上的变慢，有人专门做过 benchmark，大概是 40~50 倍的下降。 因为，finalize 被设计成在对象被垃圾收集前调用，这就意味着实现了 finalize 方法的对象是个“特殊公民”，JVM 要对它进行额外处理。finalize 本质上成为了快速回收的阻碍者，可能导致你的对象经过多个垃圾收集周期才能被回收。 有人也许会问，我用 System.runFinalization() 告诉 JVM 积极一点，是不是就可以了？也许有点用，但是问题在于，这还是不可预测、不能保证的，所以本质上还是不能指望。实践中，因为 finalize 拖慢垃圾收集，导致大量对象堆积，也是一种典型的导致 OOM (OutOfMemoryError ) 的原因。 从另一个角度，我们要确保回收资源就是因为资源都是有限的，垃圾收集时间的不可预测，可能会极大加剧资源占用。这意味着对于消耗非常高频的资源，千万不要指望 finalize 去承担资源释放的主要职责，最多让 finalize 作为最后的“守门员”，况且它已经暴露了如此多的问题。推荐是：资源用完即显式释放，或者利用资源池来尽量重用。 finalize 还会掩盖资源回收时的出错信息，我们看下面一段 JDK 的源代码，截取自 java.lang.ref.Finalizer 12345678910111213private void runFinalizer(JavaLangAccess jla) &#123;// ... 省略部分代码try &#123; Object finalizee = this.get(); if (finalizee != null &amp;&amp; !(finalizee instanceof java.lang.Enum)) &#123; jla.invokeFinalize(finalizee); // Clear stack slot containing this variable, to decrease // the chances of false retention with a conservative GC finalizee = null; &#125; &#125; catch (Throwable x) &#123; &#125; super.clear(); &#125; 这里的Throwable 是被生吞了的！也就意味着一旦出现异常或者出错，你得不到任何有效信息。况且，Java 在 finalize 阶段也没有好的方式处理任何信息，不然更加不可预测。","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"java基础","slug":"java基础","permalink":"http://www.kuanger.top/tags/java基础/"}]},{"title":"Exception和Error的区别","slug":"backend/java_基础/Exception和Error的区别","date":"2018-12-27T16:00:00.000Z","updated":"2018-12-30T11:35:36.240Z","comments":true,"path":"2018/12/28/backend/java_基础/Exception和Error的区别/","link":"","permalink":"http://www.kuanger.top/2018/12/28/backend/java_基础/Exception和Error的区别/","excerpt":"典型回答Exception 和 Error 都是继承了 Throwable 类，在 Java 中只有 Throwable 类型的实例才可以被抛出（throw） 或者捕获（catch），它是异常处理机制的基本组成类型。 Exception 和 Error 体现了 Java 平台设计者对不同异常情况的分类。 Exception 是程序正常运行中，可以预料的意外情况，可能并且应该被捕获，进行相应处理。 Error 是指在正常情况下，不大可能出现的情况，绝大部分的 Error 都会导致程序（比如 JVM 自身）处于非正常的、不可恢复状态。既然是非正常情况，所以不便于也不需要捕获，常见的比如 OutOfMemoryError 之类，都是 Error 的子类。","text":"典型回答Exception 和 Error 都是继承了 Throwable 类，在 Java 中只有 Throwable 类型的实例才可以被抛出（throw） 或者捕获（catch），它是异常处理机制的基本组成类型。 Exception 和 Error 体现了 Java 平台设计者对不同异常情况的分类。 Exception 是程序正常运行中，可以预料的意外情况，可能并且应该被捕获，进行相应处理。 Error 是指在正常情况下，不大可能出现的情况，绝大部分的 Error 都会导致程序（比如 JVM 自身）处于非正常的、不可恢复状态。既然是非正常情况，所以不便于也不需要捕获，常见的比如 OutOfMemoryError 之类，都是 Error 的子类。 Exception 又分为可检查（checked）异常和不检查（unchecked）异常，可检查异常在源代码里必须显式地进行捕获处理，这是编译期检查的一部分。不检查异常就是所谓的运行时异常，具体根据需要来判断是否需要捕获，并不会在编译期强制要求。 checked exception ：Java编译器要求对检查异常必须捕获或抛出，代码逻辑没有错误，但程序运行时会因为IO等错误导致异常，你在编写程序阶段是预料不到的。如果不处理这些异常，程序将来肯定会出错。所以编译器会提示你要去捕获并处理这种可能发生的异常，不处理就不能通过编译 （可以简单理解为指的是编译时异常） unchecked exception：Java编译器不要求对未检查异常一定捕获或抛出，可以不做处理。此类异常通常是在逻辑上有错误，具体根据需要来判断是否需要捕获，并不会在编译期强制要求。(可以简单理解为指的是运行时异常) NoClassDefFoundError 和 ClassNotFoundException 有什么区别NoClassDefFoundError是一个错误(Error)，而ClassNOtFoundException是一个异常，在Java中对于错误和异常的处理是不同的，我们可以从异常中恢复程序但却不应该尝试从错误中恢复程序。 ClassNotFoundException 的产生原因： Java支持使用Class.forName方法来动态地加载类，任意一个类的类名如果被作为参数传递给这个方法都将导致该类被加载到JVM内存中，如果这个类在类路径中没有被找到，那么此时就会在运行时抛出 ClassNotFoundException 异常。 解决该问题 需要确保所需的类连同它依赖的包存在于类路径中，常见问题在于类名书写错误。 另外还有一个导致 ClassNotFoundException 的原因就是：当一个类已经某个类加载器加载到内存中了，此时另一个类加载器又尝试着动态地从同一个包中加载这个类。通过控制动态类加载过程，可以避免上述情况发生。 NoClassDefFoundError 产生的原因在于： 如果 JVM 或者 ClassLoader 实例尝试加载（可以通过正常的方法调用，也可能是使用new来创建新的对象）类的时候却找不到类的定义。要查找的类在编译的时候是存在的，运行的时候却找不到了。这个时候就会导致 NoClassDefFoundError. 解决该问题 可能是打包过程漏掉了部分类，或者jar包出现损坏或者篡改。 查找那些在开发期间存在于类路径下但在运行期间却不在类路径下的类。 注意事项先看一段代码：1234567try &#123; // 业务代码 // … Thread.sleep(1000L);&#125; catch (Exception e) &#123; // Ignore it&#125; 这段代码虽然很短，但是已经违反了异常处理的两个基本原则。 尽量捕获特定异常尽量不要捕获类似 Exception 这样的通用异常，而是应该捕获特定异常，在这里是 Thread.sleep() 抛出的 InterruptedException。 这是因为在日常的开发和合作中，我们读代码的机会往往超过写代码，软件工程是门协作的艺术，所以我们有义务让自己的代码能够直观地体现出尽量多的信息，而泛泛的 Exception 之类，恰恰隐藏了我们的目的。 另外，我们也要保证程序不会捕获到我们不希望捕获的异常。比如，你可能更希望 RuntimeException 被扩散出来，而不是被捕获。 进一步讲，除非深思熟虑了，否则不要捕获 Throwable 或者 Error，这样很难保证我们能够正确程序处理 OutOfMemoryError。 或者另一个角度说，捕获异常的范围应该是由小到大的范围。 不要生吞（swallow）异常不要生吞（swallow）异常。这是异常处理中要特别注意的事情，因为很可能会导致非常难以诊断的诡异情况。 如果我们不把异常抛出来，或者也没有输出到日志（Logger）之类，程序可能在后续代码以不可控的方式结束。没人能够轻易判断究竟是哪里抛出了异常，以及是什么原因产生了异常。 完整正确输出异常错误打印再来看看第二段代码123456try &#123; // 业务代码 // …&#125; catch (IOException e) &#123; e.printStackTrace();&#125; 这段代码作为一段实验代码，它是没有任何问题的，但是在产品代码中，通常都不允许这样处理。你先思考一下这是为什么呢？ 我们先来看看 printStackTrace() 的文档，开头就是 “Prints this throwable and its backtrace to the standard error stream” 。问题就在这里，在稍微复杂一点的生产系统中，标准出错（STERR）不是个合适的输出选项，因为你很难判断出到底输出到哪里去了。 尤其是对于分布式系统，如果发生异常，但是无法找到堆栈轨迹（stacktrace），这纯属是为诊断设置障碍。所以，最好使用产品日志，详细地输出到日志系统里。 Throw early, catch late 原则 Throw early 12345public void readPreferences(String fileName)&#123; //...perform operations... InputStream in = new FileInputStream(fileName); //...read the preferences file...&#125; 如果 fileName 是 null，那么程序就会抛出 NullPointerException，但是由于没有第一时间暴露出问题，堆栈信息可能非常令人费解，往往需要相对复杂的定位。这个 NPE 只是作为例子，实际产品代码中，可能是各种情况，比如获取配置失败之类的。在发现问题的时候，第一时间抛出，能够更加清晰地反映问题。 我们可以修改一下判断一下fileName，让问题“throw early”，对应的异常信息就非常直观了。123456public void readPreferences(String filename) &#123; Objects. requireNonNull(filename); //...perform other operations... InputStream in = new FileInputStream(filename); //...read the preferences file...&#125; catch late 至于“catch late”，其实是我们经常苦恼的问题，捕获异常后，需要怎么处理呢？最差的处理方式，就是我前面提到的“生吞异常”，本质上其实是掩盖问题。如果实在不知道如何处理，可以选择保留原有异常的 cause 信息，直接再抛出或者构建新的异常抛出去。 在更高层面，因为有了清晰的（业务）逻辑，往往会更清楚合适的处理方式是什么。 有的时候，我们会根据需要自定义异常，这个时候除了保证提供足够的信息，还有两点需要考虑： 是否需要定义成 Checked Exception，因为这种类型设计的 初衷更是为了从异常情况恢复，作为异常设计者，我们往往有充足信息进行分类。 在保证诊断信息足够的同时，也要考虑避免包含敏感信息，因为那样可能导致潜在的安全问题。 如果我们看 Java 的标准类库，你可能注意到类似 java.net.ConnectException，出错信息是类似 “ Connection refused (Connection refused)”，而不包含具体的机器名、IP、端口等，一个重要考量就是信息安全。类似的情况在日志中也有，比如，用户数据一般是不可以输出到日志里面的。 业界有一种争论（甚至可以算是某种程度的共识），Java 语言的 Checked Exception 也许是个设计错误，反对者列举了几点： Checked Exception 的假设是我们捕获了异常，然后恢复程序。但是，其实我们大多数情况下，根本就不可能恢复。Checked Exception 的使用，已经大大偏离了最初的设计目的。（当然，很多人也觉得没有必要矫枉过正，因为确实有一些异常，比如和环境相关的 IO、网络等，其实是存在可恢复性的，而且 Java 已经通过业界的海量实践，证明了其构建高质量软件的能力。） Checked Exception 不兼容 functional 编程，如果你写过 Lambda/Stream 代码，相信深有体会。 Checked Exception 不兼容 functional 编程至于Checked Exception 不兼容 functional 编程可以简单说明一下 当我们在使用 Java 8 的 Lambda 表达式时，表达式内容需要抛出异常，也许还会想当然的让当前方法再往外抛来解决编译问题,如上图所示，但还是提示IO异常 Unhandled exception: java.io.FileNotFoundException。 但是 Lambda 本身就是一个功能性接口方法的实现，所以把上面图片的代码还原为匿名类的方式 1234567public void foo() &#123; Stream.of(\"a\", \"b\").forEach(new Consumer&lt;String&gt;() &#123; @Override public void accept(String s) &#123; new FileInputStream(s).close(); &#125;&#125;); 那怎样解决这个 check exception 呢？如果需要抛异常只能在 accept() 方法来向外层抛异常，正是因为 Consumer 定义的 accept() 方法定义不抛异常，所以只能try/catch起来。 这种情况似乎只能这样把 checked exception 转换为 unchecked exception 了。 1234567try &#123; new FileInputStream(s).close();&#125; catch (IOException e) &#123; e.printStackTrace(); //这是我加的，可以在这里抛出一个 unchecked 异常，如 throw new RuntimeException(\"file not found\");&#125; 如果不想要捕获异常再转换为 unchecked exception 的话，那就不能用 Java 8 内置的 Consumer 接口了，需要有一个声明抛出 Exception 的 accept() 方法的 Consumer. 比如下面的定义的 MyConsumer, 它的 accept() 方法抛出异常，代码如下：123456789101112@FunctionalInterface interface MyConsumer &#123; void accept(String s) throws Exception;&#125; public void foo(String f, MyConsumer consumer) throws Exception &#123; consumer.accept(f);&#125; public void client() throws Exception&#123; foo(\"a\", s -&gt; new FileInputStream(s).close());&#125; 上面的 foo() 和 client() 方法就可以声明抛出由 new FileInputStream() 产生的异常，而不需要进行异常转换。 想了解更详情可以前往浏览：https://yanbin.blog/java8-lambda-and-checked-exception/ 性能角度我们从性能角度来审视一下 Java 的异常处理机制，这里有两个可能会相对昂贵的地方： try-catch 代码段会产生额外的性能开销，或者换个角度说，它往往会影响 JVM 对代码进行优化，所以建议仅捕获有必要的代码段，尽量不要一个大的 try 包住整段的代码；与此同时，利用异常控制代码流程，也不是一个好主意，远比我们通常意义上的条件语句（if/else、switch）要低效。 Java 每实例化一个 Exception，都会对当时的栈进行快照，这是一个相对比较重的操作。如果发生的非常频繁，这个开销可就不能被忽略了。 所以，对于部分追求极致性能的底层类库，有种方式是尝试创建不进行栈快照的 Exception。这本身也存在争议，因为这样做的假设在于，我创建异常时知道未来是否需要堆栈。问题是，实际上可能吗？小范围或许可能，但是在大规模项目中，这么做可能不是个理智的选择。如果需要堆栈，但又没有收集这些信息，在复杂情况下，尤其是类似微服务这种分布式系统，这会大大增加诊断的难度。 当我们的服务出现反应变慢、吞吐量下降的时候，检查发生最频繁的 Exception 也是一种思路。","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"java基础","slug":"java基础","permalink":"http://www.kuanger.top/tags/java基础/"}]},{"title":"谈谈对Java平台的理解","slug":"backend/java_基础/谈谈对Java平台的理解","date":"2018-12-26T16:00:00.000Z","updated":"2018-12-28T15:48:48.376Z","comments":true,"path":"2018/12/27/backend/java_基础/谈谈对Java平台的理解/","link":"","permalink":"http://www.kuanger.top/2018/12/27/backend/java_基础/谈谈对Java平台的理解/","excerpt":"知其然而不知其所以然 如果谈起对Java的理解，对于这类笼统的问题，或许会稍微紧张一下，有点知其然而不知其所以然的感觉，可能不知从何说起或者回答会有稍微片面，所以今天就点到线地整理一下对Java的理解。","text":"知其然而不知其所以然 如果谈起对Java的理解，对于这类笼统的问题，或许会稍微紧张一下，有点知其然而不知其所以然的感觉，可能不知从何说起或者回答会有稍微片面，所以今天就点到线地整理一下对Java的理解。 JRE、JDK、JIT、AOT如果从java的运行开始说起，我们日常会接触到 JRE（Java Runtime Environment）或者 JDK（Java Development Kit）。 JRE，也就是 Java 运行环境，包含了 JVM 和 Java 类库，以及一些模块等。而 JDK 可以看作是 JRE 的 一个超集，提供了更多工具，比如编译器、各种诊断工具等。 Write once, run anywhere 还记得当初Java宣传的一句话吗，”Write once, run anywhere”，一次编译，到处执行，体现Java跨平台的特性。 Java的跨平台特性与Java虚拟机的存在密不可分，可在不同的环境中运行；比如说Windows平台和Linux平台都有相应的JDK，安装好JDK后也就有了Java语言的运行环境。其实Java语言本身与其他的编程语言没有特别大的差异，并不是说Java语言可以跨平台，而是在不同的平台都有可以让Java语言运行的环境而已，所以才有了Java一次编译，到处运行这样的效果。 众所周知，我们通常把Java分为编译期和运行时。这里说的Java的编译和C/C++是有着不同的意义的，Javac的编译，编译Java源码生成 .class 字节码文件，这个字节码文件是可以到处运行的，这是第一次编译；然后这个字节码文件就由JVM来进行第二次编译，转换成目标的机器代码，这就体现了跨平台特性，这个过程也是叫作Java解释执行。 跟C/C++最大的不同点在于，C/C++编程是面向操作系统的，需要开发者极大地关系不同操作系统之间的差异性；而Java平台通过JVM虚拟机屏蔽了操作系统和硬件的底层细节，使得开发者无需过多地关心不同操作系统之间的差异性。通过增加一个间接的中间层来进行“解耦”，是计算机领域非常常用的一种“艺术手法”，JVM虚拟机是这样，操作系统是这样，Http也是这样。 Java解释执行：我们开发的Java的源代码，首先通过Javac编译成字节码（bytecode），然后运行的时通过Java虚拟机（JVM）内嵌的解释器将字节码转换成最终的机器码，这就属于Java解释执行； Java编译执行：当我们常见的JVM，比如Oracle JDK提供的Hotspot JVM，都提供了JIT(Just-In-Time)编译器，也就是通常所说的动态编译器，JIT能够在运行时将热点代码编译成机器码，这种情况下部分热点代码就属于编译执行。 在运行时，JVM会通过 类加载器（Class-Loader） 加载字节码，解释或者编译执行，就像前面提到的，主流Java版本中，如JDK8实际是解释和编译混合的一种模式，即所谓的混合模式（-Xmixed）。通过运行在server模式的JVM，会进行上万次调用以收集足够的信息进行高效的编译，client模式这个门限是1500次。Oracle Hotspot JVM 内置了两个不同的 JIT compiler，C1 对应前面说的 client 模式，适用于对于启动速度敏感的应用，比如普通Java应用；C2 对应server模式，他的优化是为长时运行的服务端应用设计的。默认是采用所谓的 分层编译（TieredCompilation）。 Java 虚拟机启动时，可以指定不同的参数对运行模式进行选择。 比如，指定“-Xint”，就是告诉 JVM 只进行解释执行，不对代码进行编译，这种模式抛弃了 JIT 可能带来的性能优势。毕竟解释器（interpreter）是逐条读入，逐条解释运行的。 与其相对应的，还有一个“-Xcomp”参数，这是告诉 JVM 关闭解释器，不要进行解释执行，或者叫作最大优化级别。那你可能会问这种模式是不是最高效啊？简单说，还真未必。“-Xcomp”会导致 JVM 启动变慢非常多，同时有些 JIT 编译器优化方式，比如分支预测，如果不进行 profiling，往往并不能进行有效优化。 除了我们日常最常见的 Java 使用模式，其实还有一种新的编译方式，即所谓的 AOT（Ahead-of-Time Compilation） ，直接将字节码编译成机器代码，这样就避免了 JIT 预热等各方面的开销，比如 Oracle JDK 9 就引入了实验性的 AOT 特性，并且增加了新的 jaotc 工具。利用下面的命令把某个类或者某个模块编译成为 AOT 库。（也就是可以直接把java代码编译成机器代码运行） 12jaotc --output libHelloWorld.so HelloWorld.classjaotc --output libjava.base.so --module java.base 然后，在启动时直接指定就可以了。1java -XX:AOTLibrary=./libHelloWorld.so,./libjava.base.so HelloWorld 而且，Oracle JDK 支持分层编译和 AOT 协作使用，这两者并不是二选一的关系。如果你有兴趣，可以参考相关文档：http://openjdk.java.net/jeps/295。AOT 也不仅仅是只有这一种方式，业界早就有第三方工具（如 GCJ、Excelsior JET）提供相关功能。 知识扩展 对于 Java 平台的理解，可以从很多方面简明扼要地谈一下， 例如：Java 语言特性，包括泛型、Lambda 等语言特性；基础类库，包括集合、IO/NIO、网络、并发、安全等基础类库。 对于我们日常工作应用较多的类库，面试前可以系统化总结一下，有助于临场发挥。 或者谈谈 JVM 的一些基础概念和机制，比如 Java 的类加载机制，常用版本 JDK（如 JDK 8）内嵌的 Class-Loader，例如 Bootstrap、 Application 和 Extension Class-loader； 类加载大致过程：加载、验证、链接、初始化（这里参考了周志明的《深入理解 Java 虚拟机》，非常棒的 JVM 上手书籍）；自定义 Class-Loader 等。 还有垃圾收集的基本原理，最常见的垃圾收集器，如 SerialGC、Parallel GC、 CMS、 G1 等，对于适用于什么样的工作负载最好也心里有数。 当然还有 JDK 包含哪些工具或者 Java 领域内其他工具等，如编译器、运行时环境、安全工具、诊断和监控工具等。这些基本工具是日常工作效率的保证，对于我们工作在其他语言平台上，同样有所帮助，很多都是触类旁通的。 下图是总结的一个相对宽泛的蓝图提供参考。","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"},{"name":"JVM","slug":"java/JVM","permalink":"http://www.kuanger.top/categories/java/JVM/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"java基础","slug":"java基础","permalink":"http://www.kuanger.top/tags/java基础/"},{"name":"JVM","slug":"JVM","permalink":"http://www.kuanger.top/tags/JVM/"}]},{"title":"阿里巴巴Java开发手册中的开发规约之一(2)","slug":"backend/规约/阿里巴巴Java开发手册中的开发规约之一(2)","date":"2018-12-24T16:00:00.000Z","updated":"2019-01-14T13:32:26.196Z","comments":true,"path":"2018/12/25/backend/规约/阿里巴巴Java开发手册中的开发规约之一(2)/","link":"","permalink":"http://www.kuanger.top/2018/12/25/backend/规约/阿里巴巴Java开发手册中的开发规约之一(2)/","excerpt":"阿里巴巴Java开发手册中开发规约之一 关于基本类型与包装类型的使用标准： 【强制】所有的POJO类属性比如使用包装数据类型。 【强制】RPC方法的返回值和参数必须使用包装数据类型。 【推荐】所有的局部变量使用的基本数据类型。","text":"阿里巴巴Java开发手册中开发规约之一 关于基本类型与包装类型的使用标准： 【强制】所有的POJO类属性比如使用包装数据类型。 【强制】RPC方法的返回值和参数必须使用包装数据类型。 【推荐】所有的局部变量使用的基本数据类型。 Boolean还是boolean？我们知道，boolean是基本数据类型，而Boolean是包装类型，当在定义POJO的布尔类型变量的时候，应该使用Boolean还是boolean呢？ 12345678910111213141516171819202122232425262728public class BooleanMainTest &#123; public static void main(String[] args) &#123; Model model1 = new Model(); System.out.println(\"default model : \" + model1); &#125;&#125;class Model &#123; /** * 定一个Boolean类型的success成员变量 */ private Boolean success; /** * 定一个boolean类型的failure成员变量 */ private boolean failure; /** * 覆盖toString方法，使用Java 8 的StringJoiner */ @Override public String toString() &#123; return new StringJoiner(\", \", Model.class.getSimpleName() + \"[\",\"]\") .add(\"success=\" + success) .add(\"failure=\" + failure) .toString(); &#125;&#125; 以上代码输出结果为： 1default model : Model[success=null, failure=false] 可以看到，当我们没有设置Model对象的字段的值的时候，Boolean类型的变量会设置默认值为null，而boolean类型的变量会设置默认值为false。即对象的默认值是null，boolean基本数据类型的默认值是false。 在阿里巴巴规约中是建议我们使用包装类型为什么呢？ 举个扣费例子 我们做一个扣费系统，扣费时需要从外部的定价系统中读取一个费率的值，我们预期该接口的返回值中会包含一个浮点型的费率字段。当我们取到这个值得时候就使用公式：金额*费率=费用 进行计算，计算结果进行划扣。 如果由于计费系统异常，他可能会返回个默认值，如果这个字段是Double类型的话，该默认值为null，如果该字段是double类型的话，该默认值为0.0。 如果扣费系统对于该费率返回值没做特殊处理的话，拿到null值进行计算会直接报错，阻断程序。拿到0.0可能就直接进行计算，得出接口为0后进行扣费了。这种异常情况就无法被感知。 这种使用包装类型定义变量的方式，通过异常来阻断程序，进而可以被识别到这种线上问题。如果使用基本数据类型的话，系统可能不会报错，进而认为无异常。 以上，就是建议在POJO和RPC的返回值中使用包装类型的原因。 boolean对于NPE还有一个注意当我们在设计一个接口的时候，对于接口的返回值的定义，尽量避免使用Boolean类型来定义。大多数情况下，别人使用我们的接口返回值时可能用if(response.isSuccess){}else{}的方式，如果我们由于忽略没有设置success字段的值，就可能导致 NPE，这明显是我们不希望看到的。","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"规范","slug":"规范","permalink":"http://www.kuanger.top/tags/规范/"}]},{"title":"阿里巴巴Java开发手册中的开发规约之一(1)","slug":"backend/规约/阿里巴巴Java开发手册中的开发规约之一(1)","date":"2018-12-23T16:00:00.000Z","updated":"2019-01-14T13:32:26.197Z","comments":true,"path":"2018/12/24/backend/规约/阿里巴巴Java开发手册中的开发规约之一(1)/","link":"","permalink":"http://www.kuanger.top/2018/12/24/backend/规约/阿里巴巴Java开发手册中的开发规约之一(1)/","excerpt":"阿里巴巴Java开发手册中的开发规约之一 【强制】POJO类中布尔类型的变量，都不要加is，否则部分框架解析会引起序列化错误。 反例： 定义为基本数据类型boolean isSuccess；的属性，他的方法也是isSuccess()， RPC框架在反向解析的时候，“以为”对应的属性名是success，导致属性获取不到，进而抛出异常","text":"阿里巴巴Java开发手册中的开发规约之一 【强制】POJO类中布尔类型的变量，都不要加is，否则部分框架解析会引起序列化错误。 反例： 定义为基本数据类型boolean isSuccess；的属性，他的方法也是isSuccess()， RPC框架在反向解析的时候，“以为”对应的属性名是success，导致属性获取不到，进而抛出异常 使用success 还是 isSucces？到底应该是用success还是isSuccess来给变量命名呢？从语义上面来讲，两种命名方式都可以讲的通，并且也都没有歧义。那么还有什么原则可以参考来让我们做选择呢。 为什么会有这样的规定呢？我们看一下POJO中布尔类型变量不同的命名有什么区别吧。 123456789101112131415161718192021222324252627282930313233343536373839class Model1 &#123; private Boolean isSuccess; public void setSuccess(Boolean success) &#123; isSuccess = success; &#125; public Boolean getSuccess() &#123; return isSuccess; &#125;&#125;class Model2 &#123; private Boolean success; public Boolean getSuccess() &#123; return success; &#125; public void setSuccess(Boolean success) &#123; this.success = success; &#125;&#125;class Model3 &#123; private boolean isSuccess; public boolean isSuccess() &#123; return isSuccess; &#125; public void setSuccess(boolean success) &#123; isSuccess = success; &#125;&#125;class Model4 &#123; private boolean success; public boolean isSuccess() &#123; return success; &#125; public void setSuccess(boolean success) &#123; this.success = success; &#125;&#125; 以上代码的setter/getter是使用Intellij IDEA自动生成的，仔细观察以上代码，你会发现以下规律： 基本类型自动生成的getter和setter方法，名称都是isXXX()和setXXX()形式的。 包装类型自动生成的getter和setter方法，名称都是getXXX()和setXXX()形式的。 根据JavaBeans(TM) Specification规定，如果是普通的参数，命名为propertyName，需要通过以下方式定义其setter/getter： 12public &lt;PropertyType&gt; get&lt;PropertyName&gt;();public void set&lt;PropertyName&gt;(&lt;PropertyType&gt; a); 但是，布尔类型的变量propertyName则是另外一套命名原则的： 12public boolean is&lt;PropertyName&gt;();public void set&lt;PropertyName&gt;(boolean m); 其实看到这里已经可以发现，当我们使用了基本变量isSuccess变量的时候，生成方法名是isSuccess()的，通过isSuccess()来获取变量的值的时候，方法会认为变量名是success，总而找不到值就会出现错误。下面就举例开发中会出现的一个错误 。 序列化带来的影响我们这里拿比较常用的JSON序列化来举例，看看常用的fastJson、jackson和Gson之间有何区别： 1234567891011121314151617181920212223242526272829303132333435public class BooleanMainTest &#123; public static void main(String[] args) throws IOException &#123; //定一个Model3类型 Model3 model3 = new Model3(); model3.setSuccess(true); //使用fastjson(1.2.16)序列化model3成字符串并输出 System.out.println(\"Serializable Result With fastjson :\" + JSON.toJSONString(model3)); //使用Gson(2.8.5)序列化model3成字符串并输出 Gson gson =new Gson(); System.out.println(\"Serializable Result With Gson :\"+gson.toJson(model3)); //使用jackson(2.9.7)序列化model3成字符串并输出 ObjectMapper om = new ObjectMapper(); System.out.println(\"Serializable Result With jackson :\" +om.writeValueAsString(model3)); &#125;&#125;class Model3 implements Serializable &#123; private static final long serialVersionUID = 1836697963736227954L; private String kuanger; private boolean isSuccess; public boolean isSuccess() &#123; return isSuccess; &#125; public void setSuccess(boolean success) &#123; isSuccess = success; &#125; public String getKuanger()&#123; return \"hello\"; &#125;&#125; 输出 123Serializable Result With fastjson :&#123;\"kuanger\":\"hello\",\"success\":true&#125;Serializable Result With Gson :&#123;\"isSuccess\":true&#125;Serializable Result With jackson :&#123;\"success\":true,\"kuanger\":\"hello\"&#125; 我们可以得出结论： fastjson和jackson在把对象序列化成json字符串的时候，是通过反射遍历出该类中的所有getter方法，得到getHollis和isSuccess，然后根据JavaBeans规则，他会认为这是两个属性hollis和success的值。直接序列化成json: 1&#123;\"kuanger\":\"hello\",\"success\":true&#125; 而Gson是通过反射遍历该类中的所有属性，并把其值序列化成json: 1&#123;\"isSuccess\":true&#125; 可以看到，由于不同的序列化工具，在进行序列化的时候使用到的策略是不一样的，所以，对于同一个类的同一个对象的序列化结果可能是不同的。 现在，不同的序列化框架得到的json内容并不相同，如果对于同一个对象，我使用fastjson进行序列化，再使用Gson反序列化会发生什么？ 12345678910111213141516171819202122232425public class BooleanMainTest &#123; public static void main(String[] args) throws IOException &#123; Model3 model3 = new Model3(); model3.setSuccess(true); Gson gson =new Gson(); System.out.println(gson.fromJson(JSON.toJSONString(model3),Model3.class)); &#125;&#125;class Model3 implements Serializable &#123; private static final long serialVersionUID = 1836697963736227954L; private boolean isSuccess; public boolean isSuccess() &#123; return isSuccess; &#125; public void setSuccess(boolean success) &#123; isSuccess = success; &#125; @Override public String toString() &#123; return new StringJoiner(\", \", Model3.class.getSimpleName() + \"[\",\"]\") .add(\"isSuccess=\" + isSuccess) .toString(); &#125;&#125; 以上代码的输出 1Model3[isSuccess=false] 这和我们预期的结果完全相反，原因是因为JSON框架通过扫描所有的getter后发现有一个isSuccess方法，然后根据JavaBeans的规范，解析出变量名为success，把model对象序列化城字符串后内容为{&quot;success&quot;:true}。 根据{&quot;success&quot;:true}这个json串，Gson框架在通过解析后，通过反射寻找Model类中的success属性，但是Model类中只有isSuccess属性，所以，最终反序列化后的Model类的对象中，isSuccess则会使用默认值false。 但是，一旦以上代码发生在生产环境，这绝对是一个致命的问题。 虽然也是主观规定，但这是阿里系的Java代码的惨痛的经验教训。这个可以说是在规范来规避团队中常用库的坑。这坑的解决方法是可以修改常用库里的逻辑来尽可能“聪明”地识别情况，也可以靠这样的规范。某种意义上说规范是从上游卡住了问题的发生，比起把下游处理弄复杂更要干净一些。 所以，在定义POJO中的布尔类型的变量时，不要使用IsSuccess这种形式，而要直接使用success！","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"规范","slug":"规范","permalink":"http://www.kuanger.top/tags/规范/"}]},{"title":"实用的字符串格式化","slug":"backend/java_基础/实用的字符串格式化","date":"2018-12-19T03:57:00.000Z","updated":"2018-12-30T13:13:47.018Z","comments":true,"path":"2018/12/19/backend/java_基础/实用的字符串格式化/","link":"","permalink":"http://www.kuanger.top/2018/12/19/backend/java_基础/实用的字符串格式化/","excerpt":"String-format()String类的 format() 方法用于创建格式化的字符串以及连接多个字符串对象。熟悉C语言的同学应该记得C语言的sprintf()方法，两者有类似之处。format()方法有两种重载形式。 format(String format, Object... args) 新字符串使用本地语言环境，制定字符串格式和参数生成格式化的新字符串。 format(Locale locale, String format, Object... args) 使用指定的语言环境，制定字符串格式和参数生成格式化的字符串。","text":"String-format()String类的 format() 方法用于创建格式化的字符串以及连接多个字符串对象。熟悉C语言的同学应该记得C语言的sprintf()方法，两者有类似之处。format()方法有两种重载形式。 format(String format, Object... args) 新字符串使用本地语言环境，制定字符串格式和参数生成格式化的新字符串。 format(Locale locale, String format, Object... args) 使用指定的语言环境，制定字符串格式和参数生成格式化的字符串。 常规类型的格式化显示不同转换符实现不同数据类型到字符串的转换 转换符 说明 示例 %s 字符串类型 “mingrisoft” %c 字符类型 ‘m’ %b 布尔类型 true %d 整数类型（十进制） 99 %x 整数类型（十六进制） FF %o 整数类型（八进制） 77 %f 浮点类型 99.99 %a 十六进制浮点类型 FF.35AE %e 指数类型 9.38e+5 %g 通用浮点类型（f和e类型中较短的） %h 散列码 %% 百分比类型 ％ %n 换行符 %tx 日期与时间类型（x代表不同的日期与时间转换符 栗子12345678910111213141516171819@Testpublic void test() &#123; String str=null; str=String.format(\"Hi,%s\", \"张三\"); System.out.println(str); str=String.format(\"Hi,%s:%s.%s\", \"张三\",\"李四\",\"王五\"); System.out.println(str); System.out.printf(\"字母a的大写是：%c %n\", 'A'); System.out.printf(\"3&gt;7的结果是：%b %n\", 3&gt;7); System.out.printf(\"100的一半是：%d %n\", 100/2); System.out.printf(\"100的16进制数是：%x %n\", 100); System.out.printf(\"100的8进制数是：%o %n\", 100); System.out.printf(\"50元的书打8.5折扣是：%f 元%n\", 50*0.85); System.out.printf(\"上面价格的16进制数是：%a %n\", 50*0.85); System.out.printf(\"上面价格的指数表示：%e %n\", 50*0.85); System.out.printf(\"上面价格的指数和浮点数结果的长度较短的是：%g %n\", 50*0.85); System.out.printf(\"上面的折扣是%d%% %n\", 85); System.out.printf(\"字母A的散列码是：%h %n\", 'A'); &#125; 输出结果12345678910111213Hi,张三 Hi,张三:李四.王五 字母a的大写是：A 3&gt;7的结果是：false 100的一半是：50 100的16进制数是：64 100的8进制数是：144 50元的书打8.5折扣是：42.500000 元 上面价格的16进制数是：0x1.54p5 上面价格的指数表示：4.250000e+01 上面价格的指数和浮点数结果的长度较短的是：42.5000 上面的折扣是85% 字母A的散列码是：41 日期和事件字符串格式化字符串格式中还有%tx转换符没有详细介绍，它是专门用来格式化日期和时 间的。%tx转换符中的x代表另外的处理日期和时间格式的转换符，它们的组合能够将日期和时间格式化成多种格式。 转换符 说明 示例 c 包括全部日期和时间信息 星期六 十月 27 14:21:20 CST 2007 F “年-月-日”格式 2007-10-27 D “月/日/年”格式 10/27/07 r “HH:MM:SS PM”格式（12时制） 02:25:51 下午 T “HH:MM:SS”格式（24时制） 14:28:16 R “HH:MM”格式（24时制） 14:28 栗子12345678910111213141516@Testpublic void test()&#123; Date date=new Date(); //c的使用 System.out.printf(\"全部日期和时间信息：%tc%n\",date); //f的使用 System.out.printf(\"年-月-日格式：%tF%n\",date); //d的使用 System.out.printf(\"月/日/年格式：%tD%n\",date); //r的使用 System.out.printf(\"HH:MM:SS PM格式（12时制）：%tr%n\",date); //t的使用 System.out.printf(\"HH:MM:SS格式（24时制）：%tT%n\",date); //R的使用 System.out.printf(\"HH:MM格式（24时制）：%tR\",date); &#125; 输出结果123456全部日期和时间信息：星期一 九月 10 10:43:36 CST 2012 年-月-日格式：2012-09-10 月/日/年格式：09/10/12 HH:MM:SS PM格式（12时制）：10:43:36 上午 HH:MM:SS格式（24时制）：10:43:36 HH:MM格式（24时制）：10:43","categories":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/categories/java/"}],"tags":[{"name":"java","slug":"java","permalink":"http://www.kuanger.top/tags/java/"},{"name":"string","slug":"string","permalink":"http://www.kuanger.top/tags/string/"}]},{"title":"Jsoup的学习(二)_案例","slug":"spider/Jsoup的学习--(二)案例","date":"2018-12-11T03:57:00.000Z","updated":"2018-12-30T11:34:58.219Z","comments":true,"path":"2018/12/11/spider/Jsoup的学习--(二)案例/","link":"","permalink":"http://www.kuanger.top/2018/12/11/spider/Jsoup的学习--(二)案例/","excerpt":"需要学习对页面的数据进行爬取，以下内容仅供学习demo，非商业用途。","text":"需要学习对页面的数据进行爬取，以下内容仅供学习demo，非商业用途。 案例举例一 举例：获取携程的酒店名称 1234567891011@Testpublic void test1()&#123; String url = \"http://hotels.ctrip.com/hotel/701612.html\"; Document document = Jsoup.connect(url) .timeout(10000) .referrer(\"http://hotels.ctrip.com\") .get(); System.out.println(document); Elements elements = document.select(\".cn_n\"); System.out.println(\"酒店名称：\"+elements.text());&#125; 输出 123456789...&lt;div class=\"htl_info\" id=\"J_htl_info\"&gt; &lt;div class=\"name\" itemtype=\"//schema.org/Hotel\"&gt; &lt;h2 class=\"cn_n\" itemprop=\"name\"&gt;河南大厦&lt;/h2&gt; &lt;h2 class=\"en_n\"&gt;Beijing Henan Plaza Hotel&lt;/h2&gt; &lt;span id=\"ctl00_MainContentPlaceHolder_commonHead_span_hotel_medal\" data-role=\"title\" class=\"medal \" title=\"\" rstar=\"2\" cpr=\"0\"&gt;&lt;/span&gt; &lt;span class=\"medal ico_quality_gold\" title=\"确认订单更快速，入住过程更顺利，携程服务品质认证。\" style=\"display:none\" id=\"J_ServiceScoreIcon\"&gt;品质保障&lt;/span&gt; &lt;/div&gt; ... 通过标签选择器定位就可以了,效果和element可以看上图 1酒店名称：河南大厦 举例二 举例：获取酒店详情中房型的价格 寻找url 由于酒店房型数据是Ajax的，需要在开发者工具中（F12）寻找url1234567原url：http://hotels.ctrip.com/Domestic/tool/AjaxHote1RoomListForDetai1.aspx?psid=&amp;MasterHotelID=701612&amp;hotel=701612&amp;EDM=F&amp;roomId=&amp;IncludeRoom=&amp;city=1&amp;showspothotel=T&amp;supplier=&amp;IsDecoupleSpotHotelAndGroup=F&amp;contrast=0&amp;brand=0&amp;startDate=2018-12-10&amp;depDate=2018-12-11&amp;IsFlash=F&amp;RequestTravelMoney=F&amp;hsids=&amp;IsJustConfirm=&amp;contyped=0&amp;priceInfo=-1&amp;equip=&amp;filter=&amp;productcode=&amp;couponList=&amp;abForHuaZhu=&amp;defaultLoad=T&amp;esfiltertag=&amp;estagid=&amp;Currency=&amp;Exchange=&amp;TmFromList=F&amp;RoomGuestCount=1,1,0&amp;eleven=1a82f6826ef6f79f8b687d200c8bc26bc83f5fd6e22ce188fa46c37e596ada0f&amp;callback=CASZypaSpRGHqDDaCsI&amp;_=1544406910108//然后进行测试缩小请求参数范围最后url：http://hotels.ctrip.com/Domestic/tool/AjaxHote1RoomListForDetai1.aspx?MasterHotelID=701615&amp;hotel=701615&amp;startDate=2018-12-10&amp;depDate=2018-12-11//范围只需要改动酒店id和入住时间即可 设置请求头参数 如果对请求的来源做了判断就需要在header设置referrer参数 寻找规律 每一行的价格都是放在tr标签中的其中一个td中，仔细观察里面有span标签有base_price属性，直接属性选择器定位获取text，后续在正则取值。 123456789@Testpublic void test2()&#123; String url2 = \"http://hotels.ctrip.com/Domestic/tool/AjaxHote1RoomListForDetai1.aspx?MasterHotelID=701615&amp;hotel=701615&amp;startDate=2018-12-10&amp;depDate=2018-12-11\"; Document document = Jsoup.connect(url2) .timeout(10000) .referrer(\"http://hotels.ctrip.com\").get(); Elements select2 = element.select(\"tr td .base_price\"); System.out.println(select2.text());&#125; 输出1234¥&lt;\\/dfn&gt;1374&lt;\\/span&gt;&lt;\\/div&gt;\\u000a\\u0009 \\u000a\\u0009\\u0009\\u000a\\u0009\\u0009\\u000a\\u0009&lt;\\/p&gt;\\u000a \\u000a &lt;\\/span&gt;\\u000a&lt;\\/p&gt;\\u000a\\u0009\\u000a&lt;\\/td&gt;\\u000a¥&lt;\\/dfn&gt;942&lt;\\/span&gt;&lt;\\/div&gt;\\u000a\\u0009 \\u000a\\u0009\\u0009\\u000a\\u0009\\u0009\\u000a\\u0009&lt;\\/p&gt;\\u000a \\u000a &lt;\\/span&gt;\\u000a&lt;\\/p&gt;\\u000a\\u0009\\u000a&lt;\\/td&gt;\\u000a¥&lt;\\/dfn&gt;1140&lt;\\/span&gt;&lt;\\/div&gt;\\u000a\\u0009 \\u000a\\u0009\\u0009\\u000a\\u0009\\u0009\\u000a\\u0009&lt;\\/p&gt;\\u000a \\u000a &lt;\\/span&gt;\\u000a&lt;\\/p&gt;\\u000a\\u0009\\u000a&lt;\\/td&gt;\\u000a¥&lt;\\/dfn&gt;849&lt;\\/span&gt;&lt;\\/div&gt;\\u000a\\u0009 \\u000a\\u0009\\u0009\\u000a\\u0009\\u0009\\u000a\\u0009&lt;\\/p&gt;\\u000a \\u000a &lt;\\/span&gt;\\u000a&lt;\\/p&gt;\\u000a\\u0009\\u000a&lt;\\/td&gt;\\u000a 正则取值 对dfn标签后的值进行匹配取值 1234567891011121314151617@Testpublic void test3()&#123; String url2 = \"http://hotels.ctrip.com/Domestic/tool/AjaxHote1RoomListForDetai1.aspx?MasterHotelID=701615&amp;hotel=701615&amp;startDate=2018-12-10&amp;depDate=2018-12-11\"; Document document = Jsoup.connect(url2) .timeout(10000) .referrer(\"http://hotels.ctrip.com\").get(); Elements select = element.select(\"tr td .base_price\"); for (Element element1 : select) &#123; String text = element1.text(); //¥&lt;\\/dfn&gt;1374&lt;\\/span&gt;&lt;\\/div&gt;\\u000a\\u0009... Pattern pattern = Pattern.compile(\"dfn&gt;(\\\\d+)&lt;\"); Matcher matcher = pattern.matcher(text); if(matcher.find())&#123; System.out.println(matcher.group(1)); &#125; &#125;&#125; 输出 123413749421140849","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://www.kuanger.top/categories/爬虫/"}],"tags":[{"name":"spider","slug":"spider","permalink":"http://www.kuanger.top/tags/spider/"},{"name":"爬虫","slug":"爬虫","permalink":"http://www.kuanger.top/tags/爬虫/"},{"name":"jsoup","slug":"jsoup","permalink":"http://www.kuanger.top/tags/jsoup/"}]},{"title":"Jsoup的学习一篇就够","slug":"spider/Jsoup的学习一篇就够","date":"2018-12-10T03:57:00.000Z","updated":"2018-12-30T11:34:40.599Z","comments":true,"path":"2018/12/10/spider/Jsoup的学习一篇就够/","link":"","permalink":"http://www.kuanger.top/2018/12/10/spider/Jsoup的学习一篇就够/","excerpt":"摘要Jsoup是一款比较好的Java版HTML解析器。可直接解析某个URL地址、HTML文本内容。它提供了一套非常省力的API，可通过DOM，CSS以及类似于jQuery的操作方法来取出和操作数据。 由于工作原因，需要学习对页面的数据进行爬取，以下内容仅供学习demo，非商业用途。 学习途中查询了一些资料，也发现很多工具也可以实现，有兴趣可以前往了解 然后我发现jsoup可以对响应的html数据解析,于是对jsoup进行学习","text":"摘要Jsoup是一款比较好的Java版HTML解析器。可直接解析某个URL地址、HTML文本内容。它提供了一套非常省力的API，可通过DOM，CSS以及类似于jQuery的操作方法来取出和操作数据。 由于工作原因，需要学习对页面的数据进行爬取，以下内容仅供学习demo，非商业用途。 学习途中查询了一些资料，也发现很多工具也可以实现，有兴趣可以前往了解 然后我发现jsoup可以对响应的html数据解析,于是对jsoup进行学习 Jsoup主要功能 从一个URL，文件或字符串中解析HTML； 使用DOM或CSS选择器来查找、取出数据； 可操作HTML元素、属性、文本； 环境搭建 maven依赖12345&lt;dependency&gt;&lt;groupId&gt;org.jsoup&lt;/groupId&gt;&lt;artifactId&gt;jsoup&lt;/artifactId&gt;&lt;version&gt;1.8.3&lt;/version&gt;&lt;/dependency&gt; 数据载入jsoup 可以从包括字符串、URL地址以及本地文件来加载HTML 文档，并生成Document对象实例。 Document对象（一个文档的对象模型）：文档由多个Elements和TextNodes组成 (以及其它辅助nodes：详细可查看：nodes package tree). 其继承结构如下：Document继承Element继承Node. TextNode继承 Node. 一个Element包含一个子节点集合，并拥有一个父Element。他们还提供了一个唯一的子元素过滤列表。 从字符串中输入HTML文档使用静态方法 Jsoup.parse(String html)) Jsoup.parse(String html, String baseUri)) Jsoup.parseBodyFragment(String html))12345678String html = \"&lt;html&gt;&lt;head&gt;&lt;title&gt;开源中国社区&lt;/title&gt;&lt;/head&gt;\" +\"&lt;body&gt;&lt;p&gt;这里是jsoup 项目的相关文章&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;\";Document doc = Jsoup.parse(html);//获取片段String html = \"&lt;div&gt;&lt;p&gt;Lorem ipsum.&lt;/p&gt;\";Document doc = Jsoup.parseBodyFragment(html);Element body = doc.body(); 说明 其解析器能够尽最大可能从你提供的HTML文档来创见一个干净的解析结果，无论HTML的格式是否完整。 比如没有关闭标签、隐性标签（&lt;td&gt;&lt;/td&gt;会生成&lt;table&gt;&lt;tr&gt;&lt;/&gt;&lt;/&gt;）、创建可靠的文档结构（html标签包含head 和 body，在head只出现恰当的元素） 只要解析的不是空字符串，就能返回一个结构合理的文档，其中包含(至少) 一个head和一个body元素。 一旦拥有了一个Document，你就可以使用Document中适当的方法或它父类 Element 和 Node 中的方法来取得相关数据 parseBodyFragment 方法创建一个空壳的文档，并插入解析过的HTML到body元素中。 从URL直接加载HTML文档从一个网站获取和解析一个HTML文档，并查找其中的相关数据，可以使用 Jsoup.connect(String url)方法。123456789Document doc =Jsoup.connect(\"网址/\").get();String title = doc.title();Document doc =Jsoup.connect(\"网址/\") .data(\"query\", \"Java\") //请求参数 .userAgent(\"I’mjsoup\") //设置User-Agent .cookie(\"auth\", \"token\") //设置cookie .timeout(3000) //设置连接超时时间 .post(); //使用POST方法访问URL 从文件中加载HTML文档在本机硬盘上有一个HTML文件，需要对它进行解析从中抽取数据或进行修改。可以使用静态 Jsoup.parse(File in, String charsetName, String baseUri) 方法。12File input = new File(&quot;/tmp/input.html&quot;);Document doc = Jsoup.parse(input, &quot;UTF-8&quot;, &quot;http://example.com/&quot;); 保证安全Stay safe 消除不受信任的HTML (防止XSS攻击) 在做网站的时候，经常会提供用户评论的功能。有些不怀好意的用户，会搞一些脚本到评论内容中，而这些脚本可能会破坏整个页面的行为，更严重的是获取一些机要信息，此时需要清理该HTML，以避免跨站脚本cross-site scripting攻击（XSS）。使用jsoup HTML Cleaner 方法进行清除，但需要指定一个可配置的 Whitelist。 123456@Testpublic void test()&#123; String unsafe = \"&lt;p&gt;&lt;a href='http://example.com/' onclick='stealCookies()'&gt;Link&lt;/a&gt;&lt;/p&gt;\"; String safe = Jsoup.clean(unsafe, Whitelist.basic()); // now: &lt;p&gt;&lt;a href=\"http://example.com/\" rel=\"nofollow\"&gt;Link&lt;/a&gt;&lt;/p&gt;&#125; 说明 XSS又叫CSS (Cross Site Script) ，跨站脚本攻击。 它指的是恶意攻击者往Web页面里插入恶意html代码，当用户浏览该页之时，嵌入其中Web里面的html代码会被执行，从而达到恶意攻击用户的特殊目的。XSS属于被动式的攻击，因为其被动且不好利用，所以许多人常忽略其危害性。所以我们经常只让用户输入纯文本的内容，但这样用户体验就比较差了。 一个更好的解决方法就是使用一个富文本编辑器 WYSIWYG 如 CKEditor 和 TinyMCE 。这些可以输出HTML并能够让用户可视化编辑。虽然他们可以在客户端进行校验，但是这样还不够安全，需要在服务器端进行校验并清除有害的HTML代码，这样才能确保输入到你网站的HTML是安全的。 否则，攻击者能够绕过客户端的Javascript验证，并注入不安全的HMTL直接进入您的网站。 jsoup的whitelist清理器能够在服务器端对用户输入的HTML进行过滤，只输出一些安全的标签和属性。 jsoup提供了一系列的Whitelist基本配置，能够满足大多数要求；但如有必要，也可以进行修改，不过要小心。 这个cleaner非常好用不仅可以避免XSS攻击，还可以限制用户可以输入的标签范围。 whitelist常用方法 API查看：Whitelist 方法名 简介 none() 只允许包含文本信息 basic() 允许的标签包括：a, b, blockquote, br, cite, code, dd, dl, dt, em, i, li, ol, p, pre, q, small, strike, strong, sub, sup, u, ul, 以及合适的属性 simpleText() 只允许 b, em, i, strong, u 这些标签 basicWithImages() 在 basic() 的基础上增加了图片 relaxed() 这个过滤器允许的标签最多，包括：a, b, blockquote, br, caption, cite, code, col, colgroup, dd, dl, dt, em, h1, h2, h3, h4, h5, h6, i, img, li, ol, p, pre, q, small, strike, strong, sub, sup, table, tbody, td, tfoot, th, thead, tr, u, ul 如果这五个过滤器都无法满足你的要求呢 例如你允许用户插入 flash 动画，没关系，Whitelist 提供扩展功能 例如 whitelist.addTags(“embed”,”object”,”param”,”span”,”div”); 也可调用 addAttributes 为某些元素增加属性。 数据抽取使用DOM方法来获取将HTML解析成一个Document之后，就可以使用类似于DOM的方法进行操作。 1234567891011@Testpublic void test1()&#123; File input = new File(\"/tmp/input.html\"); Document doc = Jsoup.parse(input, \"UTF-8\", \"http://example.com/\"); Element content = doc.getElementById(\"content\"); Elements selects = content.getElementsByTag(\"a\"); for (Element select : selects) &#123; String url = select.attr(\"href\"); String text = select.text(); &#125;&#125; 查找元素 方法 数据 getElementById(String id) id getElementsByTag(String tag) 标签名 getElementsByClass(String className) class名 getElementsByAttribute(String key) 属性 siblingElements() 所有的兄弟元素 firstElementSibling() 第一个兄弟元素 lastElementSibling() 最后一个兄弟元素 nextElementSibling() 下一个兄弟元素 previousElementSibling() 上一个兄弟元素 parent() 获取该元素父节点 children() 获取该元素的子元素 child(int index) 获取该元素的第几个子元素（下标从0开始 元素数据 方法 数据 attr(String key) 获取属性 attr(String key, String value) 设置属性 attributes() 获取所有属性 id() 获取该元素id className() 获取该元素class，多个class之间空格隔开 classNames() 获取所有元素的class text() 获取文本内容 text(String value) 设置文本内容 html() 获取元素内HTML html(String value) 设置元素内的HTML内容 outerHtml() 获取元素外HTML内容 data() 获取数据内容（例如：script和style标签) tag() tagName() 获取元素标签名 操作HTML和文本 方法 数据 append(String html) 添加给定的html到元素末尾 prepend(String html) 添加给定html到元素前面 appendText(String text) 创建并添加文本 prependText(String text) 创建并添加文本 appendElement(String tagName) 添加到元素末尾 prependElement(String tagName) 添加到元素前 html(String value) 设置元素值 使用选择器语法来查找元素(select)使用 Element.select(String selector) 和 Elements.select(String selector)，使用类似于CSS或jQuery的语法来查找和操作元素。 123456789@Testpublic void test2()&#123; File input = new File(\"/tmp/input.html\"); Document doc = Jsoup.parse(input, \"UTF-8\", \"http://example.com/\"); Elements links = doc.select(\"a[href]\"); //带有href属性的a元素 Elements pngs = doc.select(\"img[src$=.png]\"); //扩展名为.png的图片 Element masthead = doc.select(\"div.masthead\").first();//class等于masthead的div标签 Elements resultLinks = doc.select(\"h3.r &gt; a\"); //在h3元素之后的a元素&#125; jsoup elements对象支持类似于CSS (或jquery)的选择器语法，来实现非常强大和灵活的查找功能。 Selector选择器 基本用法 方法 数据 tagname 使用标签名来定位，例如 a ns或者tag 使用命名空间的标签定位，例如 fb:name 来查找 &lt;fb:name&gt; 元素 #id 使用元素 id 定位，例如 #logo .class 使用元素的 class 属性定位，例如 .head [attribute] 使用元素的属性进行定位，例如 [href] 表示检索具有 href 属性的所有元素 [^attr] 使用元素的属性名前缀进行定位，例如 [^data-] 用来查找 HTML5 的 dataset 属性 [attr=value] 使用属性值进行定位，例如 [width=500] 定位所有 width 属性值为 500 的元素 [attr^=value], [attr$=value], [attr*=value] 利用匹配属性值开头、结尾或包含属性值来查找元素，比如：[href*=/path/] [attr~=regex] 利用属性值匹配正则表达式来查找元素，例如 img[src~=(?i).(png/jpeg)] (是竖杠来的) * 定位所有元素 Selector选择器 组合使用 方法 数据 el#id 定位 id 值某个元素，例如 a#logo -&gt; el.class 定位 class 为指定值的元素，例如 div.head -&gt; xxxx el[attr] 定位所有定义了某属性的元素，例如 a[href]以上三个任意组合 例如 a[href]#logo 、a[name].outerlink ancestor child 查找某个元素下子元素，比如：可以用.body p 查找在”body”元素下的所有 p元素 parent &gt; child &nbsp;&nbsp; 查找某个父元素下的直接子元素，比如：可以用div.content &gt; p 查找 p 元素，也可以用body &gt; * 查找body标签下所有直接子元素 siblingA + siblingB &nbsp;&nbsp; 查找在A元素之前第一个同级元素B，比如：div.head + div siblingA ~ siblingX&nbsp;&nbsp; 查找A元素之前的同级X元素，比如：h1 ~ p el, el, el 多个选择器组合，查找匹配任一选择器的唯一元素，例如：div.masthead, div.logo 伪选择器selectors (表达式) 方法 数据 :lt(n) 查找哪些元素的同级索引值（它的位置在DOM树中是相对于它的父节点）小于n，比如：td:lt(3) 表示小于三列的元素 :gt(n) 查找哪些元素的同级索引值大于n，比如： div p:gt(2)表示哪些div中有包含2个以上的p元素 :eq(n) 查找哪些元素的同级索引值与n相等，比如：form input:eq(1)表示包含一个input标签的Form元素 :has(seletor) 查找匹配选择器包含元素的元素，比如：div:has(p)表示哪些div包含了p元素 :not(selector) 查找与选择器不匹配的元素，比如： div:not(.logo) 表示不包含 class=”logo” 元素的所有 div 列表 :contains(text) 查找包含给定文本的元素，不区分大不写，比如： p:contains(jsoup) :containsOwn(text) 查找文本信息完全等于指定条件的元素 :matches(regex) 使用正则表达式进行文本过滤：div:matches((?i)login) :matchesOwn(regex) 使用正则表达式找到自身的文本 注意：上述伪选择器索引是从0开始的，也就是说第一个元素索引值为0，第二个元素index为1等 从元素抽取属性，文本和HTML Node.attr(String key) 获取属性值 Element.text() 获取元素中的文本值 Element.html() 获取元素HTML内容 Node.outerHtml() 获取元素HTML内容123456789101112@Testpublic void test3()&#123; String html = \"&lt;p&gt;An &lt;a href='http://www.baidu.com/'&gt;&lt;b&gt;baidu&lt;/b&gt;&lt;/a&gt; link.&lt;/p&gt;\"; Document doc = Jsoup.parse(html);//解析HTML字符串返回一个Document实现 Element link = doc.select(\"a\").first();//查找第一个a元素 String text = doc.body().text(); // \"An baidu link\"//取得字符串中的文本 String linkHref = link.attr(\"href\"); // \"http://www.baidu.com/\"//取得链接地址 String linkText = link.text(); // \"baidu\"\"//取得链接地址中的文本 String linkOuterH = link.outerHtml(); // \"&lt;a href=\"http://www.baidu.com\"&gt;&lt;b&gt;baidu&lt;/b&gt;&lt;/a&gt;\" String linkInnerH = link.html(); // \"&lt;b&gt;baidu&lt;/b&gt;\"//取得链接内的html内容&#125; 处理URLs有一个包含相对URLs路径的HTML文档，需要将这些相对路径转换成绝对路径的URLs。 在解析文档时确保有指定baseURI， 然后使用 abs: 属性前缀来取得包含baseURI的绝对路径 12345678@Testpublic void test5()&#123; Document doc = Jsoup.connect(\"http://www.baidu.com\").get(); Element link = doc.select(\"a\").first(); String relHref = link.attr(\"href\"); // url是 \"/\" String absHref = link.attr(\"abs:href\"); // 转换成绝对路径:\"http://www.baidu.com/\" String absHref = link.absUrl(\"href\"); // 转换成绝对路径:\"http://www.baidu.com/\"&#125; 数据修改设置属性的值在解析一个Document之后可能想修改其中的某些属性值，然后再保存到磁盘或都输出到前台页面。 可以使用属性设置方法 Element.attr(String key, String value), 和 Elements.attr(String key, String value). 假如你需要修改一个元素的 class 属性，可以使用 Element.addClass(String className) 和Element.removeClass(String className) 方法。 Elements 提供了批量操作元素属性和class的方法，比如：要为div中的每一个a元素都添加一个rel=”nofollow” 可以使用如下方法： 1doc.select(&quot;div.comments a&quot;).attr(&quot;rel&quot;, &quot;nofollow&quot;); 说明：与Element 中的其它方法一样，attr 方法也是返回当前 Element (或在使用选择器是返回 Elements 集合)。这样能够很方便使用方法连用的书写方式。比如： 1doc.select(&quot;div.masthead&quot;).attr(&quot;title&quot;, &quot;jsoup&quot;).addClass(&quot;round-box&quot;); 设置一个元素的HTML内容1234567891011@Testpublic void test6()&#123; Element div = doc.select(\"div\").first(); // &lt;div&gt;&lt;/div&gt; div.html(\"&lt;p&gt;lorem ipsum&lt;/p&gt;\"); // &lt;div&gt;&lt;p&gt;lorem ipsum&lt;/p&gt;&lt;/div&gt; div.prepend(\"&lt;p&gt;First&lt;/p&gt;\");//在div前添加html内容 div.append(\"&lt;p&gt;Last&lt;/p&gt;\");//在div之后添加html内容 // 添完后的结果: &lt;div&gt;&lt;p&gt;First&lt;/p&gt;&lt;p&gt;lorem ipsum&lt;/p&gt;&lt;p&gt;Last&lt;/p&gt;&lt;/div&gt; Element span = doc.select(\"span\").first(); // &lt;span&gt;One&lt;/span&gt; span.wrap(\"&lt;li&gt;&lt;a href='http://example.com/'&gt;&lt;/a&gt;&lt;/li&gt;\"); // 添完后的结果: &lt;li&gt;&lt;a href=\"http://example.com\"&gt;&lt;span&gt;One&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;&#125; Element.html(String html) 这个方法将先清除元素中的HTML内容，然后用传入的HTML代替。 Element.prepend(String first) 和 Element.append(String last) 方法用于在分别在元素内部HTML的前面和后面添加HTML内容 Element.wrap(String around) 对元素包裹一个外部HTML内容。 设置元素的文本内容12345678@Testpublic void test7()&#123; Element div = doc.select(\"div\").first(); // &lt;div&gt;&lt;/div&gt; div.text(\"five &gt; four\"); // &lt;div&gt;five &amp;gt; four&lt;/div&gt; div.prepend(\"First \"); div.append(\" Last\"); // now: &lt;div&gt;First five &amp;gt; four Last&lt;/div&gt;&#125; Element.text(String text) 将清除一个元素中的内部HTML内容，然后提供的文本进行代替 Element.prepend(String first) 和 Element.append(String last) 将分别在元素的内部html前后添加文本节点。 案例案例可以前往浏览第二篇 Jsoup的学习(二)–案例 参考 jsoup开发指南,jsoup中文使用手册,jsoup中文文档 jsoup官方文档 org.jsoup.nodes.Element的API Jsoup学习总结","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://www.kuanger.top/categories/爬虫/"}],"tags":[{"name":"spider","slug":"spider","permalink":"http://www.kuanger.top/tags/spider/"},{"name":"爬虫","slug":"爬虫","permalink":"http://www.kuanger.top/tags/爬虫/"},{"name":"jsoup","slug":"jsoup","permalink":"http://www.kuanger.top/tags/jsoup/"}]},{"title":"Redis的学习_基础数据结构（二）(可能是最完善的整理)","slug":"redis/Redis的学习_基础数据结构（二）","date":"2018-12-05T03:57:00.000Z","updated":"2018-12-30T11:35:09.383Z","comments":true,"path":"2018/12/05/redis/Redis的学习_基础数据结构（二）/","link":"","permalink":"http://www.kuanger.top/2018/12/05/redis/Redis的学习_基础数据结构（二）/","excerpt":"Redis 基础数据结构Redis 有 5 种基础数据结构，分别为： string (字符串) list (列表) hash (哈希) set (集合) zset (有序集合) Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。不同类型的数据结构的差异就在于 value 的结构不一样。","text":"Redis 基础数据结构Redis 有 5 种基础数据结构，分别为： string (字符串) list (列表) hash (哈希) set (集合) zset (有序集合) Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。不同类型的数据结构的差异就在于 value 的结构不一样。 String (字符串)字符串 string 是 Redis 最简单的数据结构。 字符串结构使用非常广泛，一个常见的用途就是缓存用户信息。我们将用户信息结构体使用 JSON 序列化成字符串，然后将序列化后的字符串塞进 Redis 来缓存。同样，取用户信息会经过一次反序列化的过程。 存储容量会自动扩容 Redis 的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配，如图中所示，内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。 操作 键值对 12345678910111213141516&gt; set name kuangerOK&gt; get name\"kuanger\"&gt; getset name kuanger2 # 取值后再赋值\"kuanger\"&gt; get name\"kuanger2\"&gt; exists name(integer) 1&gt; getrange name 0 2 # 获取字符串的[start end]的字符\"kua\"&gt; del name(integer) 1&gt; get name(nil) 批量键值对 12345678910111213&gt; set name1 kuanger1OK&gt; set name2 kuanger2OK&gt; mget name1 name2 name3 # 返回一个列表1) \"kuanger1\"2) \"kuanger2\"3) (nil)&gt; mset name1 boy name2 girl name3 unknown&gt; mget name1 name2 name31) \"boy\"2) \"girl\"3) \"unknown\" 过期和 set 命令扩展可以对 key 设置过期时间，到点自动删除，这个功能常用来控制缓存的失效时间。不过这个「自动删除」的机制是比较复杂的，后面会记录. 1234567891011121314151617181920212223242526&gt; set name kuanger&gt; get name\"kuanger\"&gt; expire name 5 # 设置5s 后过期(integer) 1 # 1表示设置成功，0表示变量ireader不存在... # wait for 5s&gt; ttl ireader # 查看寿命(integer) 4 # 还有4秒的寿命，返回-2表示变量不存在，-1表示没有设置过期时间&gt; get name(nil)&gt; setex name 5 kuanger # 5s 后过期，等价于 set+expire&gt; get name\"kuanger\"... # wait for 5s&gt; get name(nil)&gt; setnx name kuanger # 如果 name 不存在就执行 set 创建(integer) 1&gt; get name\"kuanger\"&gt; setnx name hello(integer) 0 # 因为 name 已经存在，所以 set 创建不成功&gt; get name\"kuanger\" # 没有改变 计数 如果 value 值是一个整数，还可以对它进行自增操作。自增是有范围的，它的范围是 signed long 的最大最小值，超过了这个值，Redis 会报错。 1234567891011121314&gt; set age 30OK&gt; incr age # 默认加一(integer) 31&gt; decr ireader # 等价于decrby ireader 1(integer) 30&gt; incrby age 6(integer) 36&gt; incrby age -5(integer) 31&gt; set codehole 9223372036854775807 # Long.MaxOK&gt; incr codehole(error) ERR increment or decrement would overflow List(列表)Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)，这点让人非常意外。 当列表弹出了最后一个元素之后，该数据结构自动被删除，内存被回收。 Redis 的列表结构常用来做 异步队列 使用。将需要延后处理的任务结构体序列化成字符串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理。 负下标 : 链表元素的位置使用自然数0,1,2,….n-1表示，还可以使用负数-1,-2,…-n来表示，-1表示「倒数第一」，-2表示「倒数第二」，那么-n就表示第一个元素，对应的下标为0。 操作 队列／堆栈 : 链表可以从表头和表尾追加和移除元素，结合使用rpush/rpop/lpush/lpop四条指令，可以将链表作为队列或堆栈使用，左向右向进行都可以 右边进左边出：队列 123456789101112&gt; rpush books python java golang(integer) 3&gt; llen books # 使用llen指令获取链表长度(integer) 3&gt; lpop books\"python\"&gt; lpop books\"java\"&gt; lpop books\"golang\"&gt; lpop books(nil) 右边进右边出：栈 12345678910&gt; rpush books python java golang(integer) 3&gt; rpop books\"golang\"&gt; rpop books\"java\"&gt; rpop books\"python\"&gt; rpop books(nil) 修改元素 12345678&gt; rpush ireader go java python(integer) 3&gt; lset ireader 1 javascript # 使用lset指令在指定位置修改元素。OK&gt; lrange ireader 0 -11) \"go\"2) \"javascript\"3) \"python\" 插入元素linsert : 使用linsert指令在列表的中间位置插入元素, 通过方向参数before/after来显示指示前置和后置插入。 不过让人意想不到的是linsert指令并不是通过指定位置来插入，而是通过指定具体的值。这是因为在分布式环境下，列表的元素总是频繁变动的，意味着上一时刻计算的元素下标在下一时刻可能就不是你所期望的下标了。123456789&gt; rpush ireader go java python(integer) 3&gt; linsert ireader before java ruby(integer) 4&gt; lrange ireader 0 -11) \"go\"2) \"ruby\"3) \"java\"4) \"python\" 暂时还没有在实际应用中发现插入指定的应用场景 删除元素 : 列表的删除操作也不是通过指定下标来确定元素的，你需要指定删除的最大个数以及元素的值 1234567&gt; rpush ireader go java python(integer) 3&gt; lrem ireader 1 java(integer) 1&gt; lrange ireader 0 -11) \"go\"2) \"python\" 慢操作 lindex : 访问指定位置的元素, 相当于 Java 链表的 get(int index) 方法，它需要对链表进行遍历，性能随着参数index增大而变差。 lrange : 使用lrange指令来获取链表子元素列表，提供start和end下标参数 ltrim : 和字面上的含义不太一样，个人觉得它叫 lretain(保留) 更合适一些，因为 ltrim 跟的两个参数start_index和end_index定义了一个区间，在这个区间内的值，ltrim 要保留，区间之外统统砍掉。我们可以通过ltrim来实现一个定长的链表，这一点非常有用。 index : 可以为负数，index=-1表示倒数第一个元素，同样index=-2表示倒数第二个元素。 1234567891011121314151617&gt; rpush books python java golang(integer) 3&gt; lindex books 1 # O(n) 慎用\"java\"&gt; lrange books 0 -1 # 获取所有元素，O(n) 慎用1) \"python\"2) \"java\"3) \"golang\"&gt; ltrim books 1 -1 # O(n) 慎用 保留[1,-1]区间的值,第一个到最后一个OK&gt; lrange books 0 -11) \"java\"2) \"golang\"&gt; ltrim books 1 0 # 这其实是清空了整个列表，因为区间范围长度为负OK&gt; llen books(integer) 0 内部结构 快速列表 quicklist 如果再深入一点，你会发现 Redis 底层存储的还不是一个简单的 linkedlist，而是称之为快速链表 quicklist 的一个结构。 首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 ziplist，也即是压缩列表。 它将所有的元素紧挨着一起存储，分配的是一块连续的内存。 当数据量比较多的时候才会改成 quicklist。因为普通的链表需要的附加指针空间太大，会比较浪费空间，而且会加重内存的碎片化。 比如这个列表里存的只是 int 类型的数据，结构上还需要两个额外的指针 prev 和 next 。所以 Redis 将链表和 ziplist 结合起来组成了 quicklist。也就是将多个 ziplist 使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。&gt; hash (字典) Redis 的字典相当于 Java 语言里面的 HashMap，它是无序字典。内部实现结构上同 Java 的 HashMap 也是一致的，同样的数组 + 链表二维结构。第一维 hash 的数组位置碰撞时，就会将碰撞的元素使用链表串接起来。 结构上它使用二维结构，第一维是数组，第二维是链表，hash的内容key和value存放在链表中，数组里存放的是链表的头指针。 通过key查找元素时，先计算key的hashcode，然后用hashcode对数组的长度进行取模定位到链表的表头，再对链表进行遍历获取到相应的value值，链表的作用就是用来将产生了「hash碰撞」的元素串起来。 哈希的第一维数组的长度也是2^n。 不同的是，Redis 的字典的值只能是字符串，另外它们 rehash 的方式不一样，因为 Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。Redis 为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。 rehash : 重新散列, 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 新计算的哈希表的指定位置上。 Redis设计与实现——哈希表的扩展与收缩 美团针对Redis Rehash机制的探索和实践 HashMap的Rehash 缩容 Redis的hash结构不但有扩容还有缩容，从这一点出发，它要比Java的HashMap要厉害一些，Java的HashMap只有扩容。缩容的原理和扩容是一致的，只不过新的数组大小要比旧数组小一倍 渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个 hash 结构，然后在后续的定时任务中以及 hash 操作指令中，循序渐进地将旧 hash 的内容一点点迁移到新的 hash 结构中。当搬迁完成了，就会使用新的hash结构取而代之。 当 hash 移除了最后一个元素之后，该数据结构自动被删除，内存被回收。 hash 结构也可以用来存储用户信息，不同于字符串一次性需要全部序列化整个对象，hash 可以对用户结构中的每个字段单独存储。这样当我们需要获取用户信息时可以进行部分获取。而以整个字符串的形式去保存用户信息的话就只能一次性全部读取，这样就会比较浪费网络流量。 hash 也有缺点，hash 结构的存储消耗要高于单个字符串，到底该使用 hash 还是字符串，需要根据实际情况再三权衡。 操作 插入元素 123456789# hset key field value &gt; hset books java \"think in java\" # 命令行的字符串如果包含空格，要用引号括起来(integer) 1&gt; hset books golang \"concurrency in go\"(integer) 1&gt; hset books python \"python cookbook\"(integer) 1&gt; hmset books java \"effective java\" python \"learning python\" golang \"modern golang programming\" # 批量 setOK 获取元素 123456789101112131415&gt; hgetall books # entries()，key 和 value 间隔出现1) \"java\"2) \"think in java\"3) \"golang\"4) \"concurrency in go\"5) \"python\"6) \"python cookbook\"&gt; hlen books(integer) 3&gt; hget books java\"think in java\"&gt; hset books golang \"learning go programming\" # 因为是更新操作，所以返回 0(integer) 0&gt; hget books golang\"learning go programming\" 删除元素 123456&gt; hdel books java(integer) 1&gt; hdel books golang python(integer) 2&gt; del books #直接删除key 包括对应的field-value(integer) 1 同字符串对象一样，hash 结构中的单个子 key 也可以进行计数，它对应的指令是 hincrby，和 incr 使用基本一样。12345# 如果没有key-value 会直接创建默认加1&gt; hincrby user-hello age 1(integer) 1&gt; hincrby user-hello age 1(integer) 2 判断元素是否存在 : 通常我们使用hget获得key对应的value是否为空就直到对应的元素是否存在了，不过如果value的字符串长度特别大，通过这种方式来判断元素存在与否就略显浪费，这时可以使用hexists指令。1234&gt; hmset ireader go fast java fast python slowOK&gt; hexists ireader go(integer) 1 Set (集合)Redis 的集合相当于 Java 语言里面的 HashSet，它内部的键值对是无序的唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值NULL。 当集合中最后一个元素移除之后，数据结构自动删除，内存被回收。 set 结构可以用来存储活动中奖的用户 ID，因为有去重功能，可以保证同一个用户不会中奖两次。 操作123456789101112131415161718&gt; sadd books python(integer) 1&gt; sadd books python # 重复(integer) 0&gt; sadd books java golang(integer) 2&gt; smembers books # 注意顺序，和插入的并不一致，因为 set 是无序的1) \"java\"2) \"python\"3) \"golang\"&gt; sismember books java # 查询某个 value 是否存在，相当于 contains(o) 1表示存在，0表示不存在(integer) 1&gt; sismember books rust(integer) 0&gt; scard books # 获取长度相当于 count()(integer) 3&gt; spop books # 弹出一个\"java\" zset (有序集合)zset 可能是 Redis 提供的最为特色的数据结构，它也是在面试中面试官最爱问的数据结构。它类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫做「跳跃列表」的数据结构。 zset 中最后一个 value 被移除后，数据结构自动删除，内存被回收。 zset 可以用来存粉丝列表，value 值是粉丝的用户 ID，score 是关注时间。我们可以对粉丝列表按关注时间进行排序。 zset 还可以用来存储学生的成绩，value 值是学生的 ID，score 是他的考试成绩。我们可以对成绩按分数进行排序就可以得到他的名次。 操作 命令：zadd key score value score value score value12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&gt; zadd books 9.0 \"think in java\"(integer) 1&gt; zadd books 8.9 \"java concurrency\"(integer) 1&gt; zadd books 8.6 \"java cookbook\"(integer) 1&gt; zadd books 9.1 \"think in java\" # 如果该元素已存在则会用新的分数替换原来的分数。(integer) 0 # 返回0则是更新&gt; zrange books 0 -1 # 按 score 排序列出，参数区间为排名范围 (从低到高) 不带score1) \"java cookbook\"2) \"java concurrency\"3) \"think in java\"&gt; zrange books 0 -1 withscores # 按 score 排序列出，参数区间为排名范围 (从低到高) 带score1) \"java cookbook\"2) \"8.6\"3) \"java concurrency\"4) \"8.9\"5) \"think in java\"6) \"9.0\"&gt; zrevrange books 0 -1 # 按 score 逆序列出，参数区间为排名范围 (从高到低) 不带score1) \"think in java\"2) \"java concurrency\"3) \"java cookbook\"&gt; zrevrange books 0 -1 withscores # 按 score 逆序列出，参数区间为排名范围 (从高到低) 带score1) \"think in java\"2) \"9.0\"3) \"java concurrency\"4) \"8.9\"5) \"java cookbook\"6) \"9.0\"&gt; zcard books # 相当于 count()(integer) 3&gt; zscore books \"java concurrency\" # 获取指定 value 的 score\"8.9000000000000004\" # 内部 score 使用 double 类型进行存储，所以存在小数点精度问题&gt; zrank books \"java concurrency\" # 排名(integer) 1&gt; zrangebyscore books 0 8.91 # 根据分值区间遍历 zset1) \"java cookbook\"2) \"java concurrency\"&gt; zrangebyscore books -inf 8.91 withscores # 根据分值区间 (-∞, 8.91] 遍历 zset，同时返回分值。inf 代表 infinite，无穷大的意思。1) \"java cookbook\"2) \"8.5999999999999996\"3) \"java concurrency\"4) \"8.9000000000000004\"&gt; zrem books \"java concurrency\" # 删除 value(integer) 1&gt; zrange books 0 -11) \"java cookbook\"2) \"think in java\" 跳跃列表zset 内部的排序功能是通过「跳跃列表」数据结构来实现的，它的结构非常特殊，也比较复杂。 因为 zset 要支持随机的插入和删除，所以它不好使用数组来表示。我们先看一个普通的链表结构。 我们需要这个链表按照 score 值进行排序。这意味着当有新元素需要插入时，要定位到特定位置的插入点，这样才可以继续保证链表是有序的。通常我们会通过二分查找来找到插入点，但是二分查找的对象必须是数组，只有数组才可以支持快速位置定位，链表做不到，那该怎么办？ 想想一个创业公司，刚开始只有几个人，团队成员之间人人平等，都是联合创始人。随着公司的成长，人数渐渐变多，团队沟通成本随之增加。这时候就会引入组长制，对团队进行划分。每个团队会有一个组长。开会的时候分团队进行，多个组长之间还会有自己的会议安排。公司规模进一步扩展，需要再增加一个层级 —— 部门，每个部门会从组长列表中推选出一个代表来作为部长。部长们之间还会有自己的高层会议安排。 跳跃列表就是类似于这种层级制，最下面一层所有的元素都会串起来。然后每隔几个元素挑选出一个代表来，再将这几个代表使用另外一级指针串起来。然后在这些代表里再挑出二级代表，再串起来。最终就形成了金字塔结构。 想想你老家在世界地图中的位置：亚洲–&gt;中国-&gt;XX省-&gt;XX市-&gt;XX县-&gt;XX镇-&gt;XX村-&gt;xxxx号，也是这样一个类似的结构。 「跳跃列表」之所以「跳跃」，是因为内部的元素可能「身兼数职」，比如上图中间的这个元素，同时处于 L0、L1 和 L2 层，可以快速在不同层次之间进行「跳跃」。 定位插入点时，先在顶层进行定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插进去。你也许会问，那新插入的元素如何才有机会「身兼数职」呢？ 跳跃列表采取一个随机策略来决定新元素可以兼职到第几层。 首先 L0 层肯定是 100% 了，L1 层只有 50% 的概率，L2 层只有 25% 的概率，L3 层只有 12.5% 的概率，一直随机到最顶层 L31 层。绝大多数元素都过不了几层，只有极少数元素可以深入到顶层。列表中的元素越多，能够深入的层次就越深，能进入到顶层的概率就会越大。 通俗的理解就是 : 需要从 header 的最高层开始遍历找到第一个节点 (最后一个比「我」小的元素)，然后从这个节点开始降一层再遍历找到第二个节点 (最后一个比「我」小的元素)，然后一直降到最底层进行遍历就找到了期望的节点 ( 最底层的最后一个比我「小」的元素 )。 我们将中间经过的一系列节点称之为 「搜索路径」 ，它是从最高层一直到最底层的每一层最后一个比「我」小的元素节点列表。 有了这个搜索路径，我们就可以插入这个新节点了。不过这个插入过程也不是特别简单。因为新插入的节点到底有多少层，得有个算法来分配一下，跳跃列表使用的是随机算法 参考 老钱的《Redis 深度历险：核心原理与应用实践》 通俗易懂的Redis数据结构基础教程","categories":[{"name":"Redis","slug":"Redis","permalink":"http://www.kuanger.top/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.kuanger.top/tags/Redis/"}]},{"title":"Redis的学习_开篇（一）","slug":"redis/Redis的学习_介绍（一）","date":"2018-12-04T03:56:55.000Z","updated":"2018-12-30T11:35:13.355Z","comments":true,"path":"2018/12/04/redis/Redis的学习_介绍（一）/","link":"","permalink":"http://www.kuanger.top/2018/12/04/redis/Redis的学习_介绍（一）/","excerpt":"摘要最近对 老钱 的 《Redis 深度历险：核心原理与应用实践》进行学习，并且一同做笔记，所以后续的Redis博客都是基于《Redis 深度历险：核心原理与应用实践》和其他的文著，再结合自己的所学到的进行结合，然后进行笔记记录，所以在此统一声明。","text":"摘要最近对 老钱 的 《Redis 深度历险：核心原理与应用实践》进行学习，并且一同做笔记，所以后续的Redis博客都是基于《Redis 深度历险：核心原理与应用实践》和其他的文著，再结合自己的所学到的进行结合，然后进行笔记记录，所以在此统一声明。 声明：笔记的参考源自钱文品老师所著《Redis 深度历险：核心原理和应用实践》，只供个人学习所用。 简单介绍安装安装Redis可以选择这5种方式： 使用 Docker 安装。 通过 Github 源码编译。 直接安装 apt-get install(Ubuntu)、yum install(RedHat) 或者 brew install(Mac)。 如果读者懒于安装操作，也可以使用网页版的 Web Redis 直接体验。 可以下载Redis绿色版直接解压可使用 操作 Docker 方式 123456# 拉取 redis 镜像&gt; docker pull redis# 运行 redis 容器&gt; docker run --name myredis -d -p6379:6379 redis# 执行容器中的 redis-cli，可以直接使用命令行操作 redis&gt; docker exec -it myredis redis-cli Github 源码编译方式 12345678910# 下载源码&gt; git clone --branch 2.8 --depth 1 git@github.com:antirez/redis.git&gt; cd redis# 编译&gt; make&gt; cd src# 运行服务器，daemonize表示在后台运行&gt; ./redis-server --daemonize yes# 运行命令行&gt; ./redis-cli 直接安装方式 12345678# mac&gt; brew install redis# ubuntu&gt; apt-get install redis# redhat&gt; yum install redis# 运行客户端&gt; redis-cli 扩展阅读 一篇Redis相关的面试文章","categories":[{"name":"Redis","slug":"Redis","permalink":"http://www.kuanger.top/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.kuanger.top/tags/Redis/"}]},{"title":"之前的笔记","slug":"something/之前的笔记","date":"2018-12-04T02:54:55.000Z","updated":"2018-12-30T11:34:55.868Z","comments":true,"path":"2018/12/04/something/之前的笔记/","link":"","permalink":"http://www.kuanger.top/2018/12/04/something/之前的笔记/","excerpt":"每天我都会阅读一到两篇的博客、人家的经验总结等等，看完后自己会做一下小笔记，笔记都做在有道云，因为手机电脑都可以随时看到，挺方便的，然后过往分享了一下笔记在 CSDN 上面， 我就不搬过来了，有兴趣可以点击去阅读：https://blog.csdn.net/Kato_op","text":"每天我都会阅读一到两篇的博客、人家的经验总结等等，看完后自己会做一下小笔记，笔记都做在有道云，因为手机电脑都可以随时看到，挺方便的，然后过往分享了一下笔记在 CSDN 上面， 我就不搬过来了，有兴趣可以点击去阅读：https://blog.csdn.net/Kato_op","categories":[{"name":"Talk","slug":"Talk","permalink":"http://www.kuanger.top/categories/Talk/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"http://www.kuanger.top/tags/笔记/"}]},{"title":"CAP理论","slug":"knowledge/CAP理论","date":"2018-12-03T03:54:55.000Z","updated":"2018-12-30T11:35:20.314Z","comments":true,"path":"2018/12/03/knowledge/CAP理论/","link":"","permalink":"http://www.kuanger.top/2018/12/03/knowledge/CAP理论/","excerpt":"前言对于分布式概念就不详细介绍了，分布式简单理解就是：一个业务分拆多个子业务，部署在不同的服务器上。 一般来说，一个子业务我们称为节点。 Content 首先，我们来看一下CAP分别代表的是什么意思： C：数据一致性(consistency) 所有节点拥有数据的最新版本 A：可用性(availability) 数据具备高可用性 P：分区容错性(partition-tolerance) 容忍网络出现分区，分区之间网络不可达。","text":"前言对于分布式概念就不详细介绍了，分布式简单理解就是：一个业务分拆多个子业务，部署在不同的服务器上。 一般来说，一个子业务我们称为节点。 Content 首先，我们来看一下CAP分别代表的是什么意思： C：数据一致性(consistency) 所有节点拥有数据的最新版本 A：可用性(availability) 数据具备高可用性 P：分区容错性(partition-tolerance) 容忍网络出现分区，分区之间网络不可达。 下面有三个节点(它们是集群的)，此时三个节点都能够相互通信： 如果出现故障由于我们的系统是分布式的，节点之间的通信是通过网络来进行的。只要是分布式系统，那很有可能会出现一种情况：因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域。 数据就散布在了这些不连通的区域中，这就叫分区 现在出现了网络分区后，此时有一个请求过来了，想要注册一个账户。 此时我们节点一和节点三是不可通信的，这就有了抉择： 如果允许当前用户注册一个账户，此时注册的记录数据只会在节点一和节点二或者节点二和节点三同步，因为节点一和节点三的记录不能同步的。 这种情况其实就是选择了可用性(availability)，抛弃了数据一致性(consistency) 如果不允许当前用户注册一个账户(就是要等到节点一和节点三恢复通信)。节点一和节点三一旦恢复通信，我们就可以保证节点拥有的数据是最新版本。 这种情况其实就是抛弃了可用性(availability)，选择了数据一致性(consistency) 再次梳理一下CAP理论一般我们说的分布式系统，P：分区容错性(partition-tolerance)这个是必需的，这是客观存在的。 CAP是无法完全兼顾的，从上面的例子也可以看出，我们可以选AP，也可以选CP。但是，要注意的是：不是说选了AP，C就完全抛弃了。不是说选了CP，A就完全抛弃了！ 在CAP理论中，C所表示的一致性是强一致性(每个节点的数据都是最新版本)，其实一致性还有其他级别的： 弱一致性：弱一致性是相对于强一致性而言，它不保证总能得到最新的值； 最终一致性(eventual consistency)：放宽对时间的要求，在被调完成操作响应后的某个时间点，被调多个节点的数据最终达成一致 可用性的值域可以定义成0到100%的连续区间。 所以，CAP理论定义的其实是在容忍网络分区的条件下，“强一致性”和“极致可用性”无法同时达到。 参考资料： 摘取文章片段 ： https://mp.weixin.qq.com/s/oTJaEFrHQi_7R68n26yfew CAP理论中的P到底是个什么意思？https://www.zhihu.com/question/54105974 浅谈分布式系统的基本问题：可用性与一致性：https://m.aliyun.com/yunqi/articles/2709 分布式系统的CAP理论：http://www.hollischuang.com/archives/666 为什么CAP理论在舍弃P的情况下，可以有完美的CA？https://www.zhihu.com/question/285878189 不懂点CAP理论，你好意思说你是做分布式的吗？http://www.yunweipai.com/archives/8432.html 扩展阅读： 浅谈分布式事务：https://m.aliyun.com/yunqi/articles/230242","categories":[{"name":"分布式/微服务理论","slug":"分布式-微服务理论","permalink":"http://www.kuanger.top/categories/分布式-微服务理论/"}],"tags":[{"name":"CAP理论","slug":"CAP理论","permalink":"http://www.kuanger.top/tags/CAP理论/"}]},{"title":"一个学习Git的有趣网站","slug":"something/一个学习Git的有趣网站","date":"2018-11-30T06:54:55.000Z","updated":"2018-12-30T11:34:54.796Z","comments":true,"path":"2018/11/30/something/一个学习Git的有趣网站/","link":"","permalink":"http://www.kuanger.top/2018/11/30/something/一个学习Git的有趣网站/","excerpt":"一个非常有趣的小网站，把Git的命令和知识点做成类似于游戏闯关一样，生动有效地帮助初步学习Git的朋友们。","text":"一个非常有趣的小网站，把Git的命令和知识点做成类似于游戏闯关一样，生动有效地帮助初步学习Git的朋友们。 网站链接：url: https://learngitbranching.js.org/?demo 在里面你能执行相应的命令，还能看到每个命令的执行情况； 通过一系列刺激的关卡挑战，逐步深入的学习 Git 的强大功能，在这个过程中你可能还会发现一些有意思的事情。 尝试了一番 他把Git的知识点都拆分成每一小块关卡，每个关卡他都会有教程和知识点的数列，如果你是初学者，从第一关开始逐个向后挑战就是了。 而如果你已经入门了，可以略过前面，直接挑战后面更有难度的关卡。 选择一个关卡之后，左边有弹框给你输入git的命令，根据知识点输入命令就可以完成了，然后可以生动有效地帮助你学习，Nice~","categories":[{"name":"Version Control","slug":"Version-Control","permalink":"http://www.kuanger.top/categories/Version-Control/"}],"tags":[{"name":"Git","slug":"Git","permalink":"http://www.kuanger.top/tags/Git/"},{"name":"funny","slug":"funny","permalink":"http://www.kuanger.top/tags/funny/"},{"name":"Version Control","slug":"Version-Control","permalink":"http://www.kuanger.top/tags/Version-Control/"}]},{"title":"Java问题快速排查","slug":"question/Java问题快速排查","date":"2018-11-30T02:54:55.000Z","updated":"2018-12-30T11:35:16.544Z","comments":true,"path":"2018/11/30/question/Java问题快速排查/","link":"","permalink":"http://www.kuanger.top/2018/11/30/question/Java问题快速排查/","excerpt":"这是一篇来源于阿里内部技术论坛的文章，原文在阿里内部获得一致好评。","text":"这是一篇来源于阿里内部技术论坛的文章，原文在阿里内部获得一致好评。 作者：红魔七号 链接：https://yq.aliyun.com/articles/69520?utm_content=m_10360 参考文章： https://mp.weixin.qq.com/s/TMAe3AyOfUQIOf0hGurR4A 原谅小弟不才，有问题可以下方留言指教~ 前言平时的工作中经常碰到很多疑难问题的处理，在解决问题的同时，有一些工具起到了相当大的作用，在此书写下来，一是作为笔记，可以让自己后续忘记了可快速翻阅，二是分享，希望看到此文的同学们可以拿出自己日常觉得帮助很大的工具，大家一起进步。 Linux命令类tail最常用的tail -f 1tail -300f shopbase.log #倒数300行并进入实时监听文件写入模式 grep12345678910grep forest f.txt #文件查找grep forest f.txt cpf.txt #多文件查找grep 'log' /home/admin -r -n #目录下查找所有符合关键字的文件cat f.txt | grep -i shopbase grep 'shopbase' /home/admin -r -n --include *.&#123;vm,java&#125; #指定文件后缀grep 'shopbase' /home/admin -r -n --exclude *.&#123;vm,java&#125; #反匹配seq 10 | grep 5 -A 3 #上匹配seq 10 | grep 5 -B 3 #下匹配seq 10 | grep 5 -C 3 #上下匹配，平时用这个就妥了cat f.txt | grep -c 'SHOPBASE' awk 基本命令 123456awk '&#123;print $4,$6&#125;' f.txtawk '&#123;print NR,$0&#125;' f.txt cpf.txt awk '&#123;print FNR,$0&#125;' f.txt cpf.txtawk '&#123;print FNR,FILENAME,$0&#125;' f.txt cpf.txtawk '&#123;print FILENAME,\"NR=\"NR,\"FNR=\"FNR,\"$\"NF\"=\"$NF&#125;' f.txt cpf.txtecho 1:2:3:4 | awk -F: '&#123;print $1,$2,$3,$4&#125;' 匹配 1234awk '/ldb/ &#123;print&#125;' f.txt #匹配ldbawk '!/ldb/ &#123;print&#125;' f.txt #不匹配ldbawk '/ldb/ &amp;&amp; /LISTEN/ &#123;print&#125;' f.txt #匹配ldb和LISTENawk '$5 ~ /ldb/ &#123;print&#125;' f.txt #第五列匹配ldb 内建变量 NR:NR表示从awk开始执行后，按照记录分隔符读取的数据次数，默认的记录分隔符为换行符，因此默认的就是读取的数据行数，NR可以理解为Number of Record的缩写。 FNR:在awk处理多个输入文件的时候，在处理完第一个文件后，NR并不会从1开始，而是继续累加，因此就出现了FNR，每当处理一个新文件的时候，FNR就从1开始计数，FNR可以理解为File Number of Record。 NF: NF表示目前的记录被分割的字段的数目，NF可以理解为Number of Field。 find12345678910111213sudo -u admin find /home/admin /tmp /usr -name \\*.log #(多个目录去找)find . -iname \\*.txt #(大小写都匹配)find . -type d #(当前目录下的所有子目录)find /usr -type l #(当前目录下所有的符号链接)find /usr -type l -name \"z*\" -ls #(符号链接的详细信息 eg:inode,目录)find /home/admin -size +250000k #(超过250000k的文件，当然+改成-就是小于了)find /home/admin f -perm 777 -exec ls -l &#123;&#125; \\; #(按照权限查询文件)find /home/admin -atime -1 #1天内访问过的文件find /home/admin -ctime -1 #1天内状态改变过的文件 find /home/admin -mtime -1 #1天内修改过的文件find /home/admin -amin -1 #1分钟内访问过的文件find /home/admin -cmin -1 #1分钟内状态改变过的文件 find /home/admin -mmin -1 #1分钟内修改过的文件 pgm批量查询vm-shopbase满足条件的日志1pgm -A -f vm-shopbase 'cat /home/admin/shopbase/logs/shopbase.log.2017-01-17|grep 2069861630' tsar tsar是alibabak开发的一个采集工具，可以上github去clone安装。他可以将历史收集到的数据持久化在磁盘上，所以我们快速来查询历史的系统数据 https://github.com/alibaba/tsar 12345678910tsar ###可以查看最近一天的各项指标tsar --live ###可以查看实时指标，默认五秒一刷tsar -d 20161218 ###指定查看某天的数据，貌似最多只能看四个月的数据tsar --memtsar --loadtsar --cpu###当然这个也可以和-d参数配合来查询某天的单个指标的情况 toptop除了看一些基本信息之外，剩下的就是配合来查询vm的各种问题了12ps -ef | grep javatop -H -p pid 获得线程10进制转16进制后jstack去抓看这个线程到底在干啥 其他12netstat -nat|awk '&#123;print $6&#125;'|sort|uniq -c|sort -rn #查看当前连接，注意close_wait偏高的情况，比如如下 排查利器btrace首当其冲的要说的是btrace。真是生产环境&amp;预发的排查问题大杀器。更详情可以移步到github：https://github.com/btraceio/btrace 查看当前谁调用了ArrayList的add方法，同时只打印当前ArrayList的size大于500的线程调用栈 监控当前服务方法被调用时返回的值以及请求的参数 注意: 经过观察，1.3.9的release输出不稳定，要多触发几次才能看到正确的结果 正则表达式匹配trace类时范围一定要控制，否则极有可能出现跑满CPU导致应用卡死的情况 由于是字节码注入的原理，想要应用恢复到正常情况，需要重启应用。 Greys说几个挺棒的功能(部分功能和btrace重合): sc -df xxx: 输出当前类的详情,包括源码位置和classloader结构 trace class method: 相当喜欢这个功能! 很早前可以早JProfiler看到这个功能。打印出当前方法调用的耗时情况，细分到每个方法。 javOSize就说一个功能 classes：通过修改了字节码，改变了类的内容，即时生效。 所以可以做到快速的在某个地方打个日志看看输出，缺点是对代码的侵入性太大。但是如果自己知道自己在干嘛，的确是不错的玩意儿。 其他功能Greys和btrace都能很轻易做的到，不说了。 JProfiler之前判断许多问题要通过 JProfiler，但是现在 Greys和 btrace基本都能搞定了。再加上出问题的基本上都是生产环境(网络隔离)，所以基本不怎么使用了，但是还是要标记一下。官网请移步https://www.ej-technologies.com/products/jprofiler/overview.html Java Tooljps m:输出主函数传入的参数. 下的hello 就是在执行程序时从命令行输入的参数 l: 输出应用程序主类完整package名称或jar完整名称. v: 列出jvm参数, -Xms20m -Xmx50m是启动程序指定的jvm参数 V: 输出通过.hotsportrc或-XX:Flags=指定的jvm参数1sudo -u admin /opt/taobao/java/bin/jps -mlvV jstack 普通用法:1sudo -u admin /opt/taobao/install/ajdk-8_1_1_fp1-b52/bin/jstack 2815 native+java栈:1sudo -u admin /opt/taobao/install/ajdk-8_1_1_fp1-b52/bin/jstack -m 2815 jinfo可看系统启动的参数，如下1sudo -u admin /opt/taobao/install/ajdk-8_1_1_fp1-b52/bin/jinfo -flags 2815 jmap 查看堆的情况 1sudo -u admin /opt/taobao/install/ajdk-8_1_1_fp1-b52/bin/jmap -heap 2815 dump 1sudo -u admin /opt/taobao/install/ajdk-8_1_1_fp1-b52/bin/jmap -dump:live,format=b,file=/tmp/heap2.bin 2815 or1sudo -u admin /opt/taobao/install/ajdk-8_1_1_fp1-b52/bin/jmap -dump:format=b,file=/tmp/heap3.bin 2815 看看堆都被谁占了? 再配合zprofiler和btrace，排查问题简直是如虎添翼 1sudo -u admin /opt/taobao/install/ajdk-8_1_1_fp1-b52/bin/jmap -histo 2815 | head -10 jstatjstat参数众多，但是使用一个就够了1sudo -u admin /opt/taobao/install/ajdk-8_1_1_fp1-b52/bin/jstat -gcutil 2815 1000 jdb时至今日，jdb也是经常使用的。jdb可以用来预发debug,假设你预发的java_home是/opt/taobao/java/，远程调试端口是8000.那么sudo -u admin /opt/taobao/java/bin/jdb -attach 8000. 出现以上代表jdb启动成功。后续可以进行设置断点进行调试。具体参数可见oracle官方说明http://docs.oracle.com/javase/7/docs/technotes/tools/windows/jdb.html CHLSDBCHLSDB感觉很多情况下可以看到更好玩的东西，不详细叙述了。 查询资料听说jstack和jmap等工具就是基于它的。1sudo -u admin /opt/taobao/java/bin/java -classpath /opt/taobao/java/lib/sa-jdi.jar sun.jvm.hotspot.CLHSDB 更详细的可见R大此贴http://rednaxelafx.iteye.com/blog/1847971 jar包冲突把这个单独写个大标题不过分吧？每个人或多或少都处理过这种烦人的case。我特么下边这么多方案不信就搞不定你?1mvn dependency:tree &gt; ~/dependency.txt 打出所有依赖 1mvn dependency:tree -Dverbose -Dincludes=groupId:artifactId 只打出指定groupId和artifactId的依赖关系 1-XX:+TraceClassLoading vm启动脚本加入。在tomcat启动脚本中可见加载类的详细信息 1-verbose vm启动脚本加入。在tomcat启动脚本中可见加载类的详细信息 1greys:sc greys的sc命令也能清晰的看到当前类是从哪里加载过来的 1tomcat-classloader-locate 通过以下url可以获知当前类是从哪里加载的 1curl http://localhost:8006/classloader/locate?class=org.apache.xerces.xs.XSObjec 其他dmesg如果发现自己的java进程悄无声息的消失了，几乎没有留下任何线索，那么dmesg一发，很有可能有你想要的。1sudo dmesg|grep -i kill|less 去找关键字oom_killer。找到的结果类似如下:12345[6710782.021013] java invoked oom-killer: gfp_mask=0xd0, order=0, oom_adj=0, oom_scoe_adj=0[6710782.070639] [&lt;ffffffff81118898&gt;] ? oom_kill_process+0x68/0x140 [6710782.257588] Task in /LXC011175068174 killed as a result of limit of /LXC011175068174 [6710784.698347] Memory cgroup out of memory: Kill process 215701 (java) score 854 or sacrifice child [6710784.707978] Killed process 215701, UID 679, (java) total-vm:11017300kB, anon-rss:7152432kB, file-rss:1232kB 以上表明，对应的java进程被系统的OOM Killer给干掉了，得分为854.解释一下OOM killer（Out-Of-Memory killer），该机制会监控机器的内存资源消耗。当机器内存耗尽前，该机制会扫描所有的进程（按照一定规则计算，内存占用，时间等），挑选出得分最高的进程，然后杀死，从而保护机器。 dmesg日志时间转换公式: log实际时间=格林威治1970-01-01+(当前时间秒数-系统启动至今的秒数+dmesg打印的log时间)秒数：1date -d \"1970-01-01 UTC `echo \"$(date +%s)-$(cat /proc/uptime|cut -f 1 -d' ')+12288812.926194\"|bc ` seconds\" 剩下的，就是看看为什么内存这么大，触发了OOM-Killer了。 eclipseMAT可作为eclipse的插件，也可作为单独的程序打开。详情请移步http://www.eclipse.org/mat/ Plugin of intellij idea key promoter maven helper 分析maven依赖的好帮手。 RateLimiter想要精细的控制QPS? 比如这样一个场景，你调用某个接口，对方明确需要你限制你的QPS在400之内你怎么控制？这个时候RateLimiter就有了用武之地。 详情可移步http://ifeve.com/guava-ratelimite Thanks~","categories":[{"name":"问题解决","slug":"问题解决","permalink":"http://www.kuanger.top/categories/问题解决/"}],"tags":[{"name":"Java","slug":"Java","permalink":"http://www.kuanger.top/tags/Java/"},{"name":"问题解决","slug":"问题解决","permalink":"http://www.kuanger.top/tags/问题解决/"}]},{"title":"Hello World","slug":"something/Hello-World","date":"2018-11-28T07:47:17.000Z","updated":"2018-12-30T11:35:05.438Z","comments":true,"path":"2018/11/28/something/Hello-World/","link":"","permalink":"http://www.kuanger.top/2018/11/28/something/Hello-World/","excerpt":"Preface Record the birth of my website 记录一下我的网站的诞生~","text":"Preface Record the birth of my website 记录一下我的网站的诞生~ Homework is stupid,the whole point is to get less of it——Rick 注意： 阅读文章的时候可以点击左上角的Logo，可以对文章的字体调整和选择夜间模式。 PrintHello World! 1System.out.print(\"Hello world\");","categories":[{"name":"welcome","slug":"welcome","permalink":"http://www.kuanger.top/categories/welcome/"}],"tags":[{"name":"welcome","slug":"welcome","permalink":"http://www.kuanger.top/tags/welcome/"}]}]}